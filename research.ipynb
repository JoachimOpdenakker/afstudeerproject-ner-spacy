{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bc159a",
   "metadata": {},
   "source": [
    "# Progress file for NER training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e075a",
   "metadata": {},
   "source": [
    "## [Installatie](#Installatie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ec817",
   "metadata": {},
   "source": [
    "### Installeer spacy in jupyter notebook env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c28127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/wolti/.local/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (52.0.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/wolti/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wolti/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wolti/.local/lib/python3.9/site-packages (from jinja2->spacy) (2.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unicode in /home/wolti/.local/lib/python3.9/site-packages (2.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ec813",
   "metadata": {},
   "source": [
    "### Installeer spacy voor windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d46cc",
   "metadata": {},
   "source": [
    "1. Installeer anaconda\n",
    "    <div>Dit geeft een goede python omgeving om in te werken.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dac5f3",
   "metadata": {},
   "source": [
    "2. Installeer spacy in de anaconda terminal\n",
    "<div class=\"alert alert-block alert-info\">conda install -c conda-forge spacy </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650f1c1",
   "metadata": {},
   "source": [
    "### Installeer spacy for linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a862f4",
   "metadata": {},
   "source": [
    "In een terminal met python geinstalleerd\n",
    "<div class=\"alert alert-block alert-info\">pip install spacy && pip install unicode</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ef020",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">Nadat u de installatie volbracht heeft kan u kiezen of u het europese of het amerikaanse model wilt gebruiken. De commandos blijven hetzelfde, deze moeten enkel in de juiste map uitgevoerd worden, EU of USA.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c9769",
   "metadata": {},
   "source": [
    "## [Extracting_data_pickle_naar_csv](#Extracting_data_pickle_naar_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e073749",
   "metadata": {},
   "source": [
    "Dit script doet hetvolgende:\n",
    "1. Dit script start met het kiezen van een pickle file.\n",
    "2. Colommen **address_1, address_2, person_ctry_code** apart nemen\n",
    "3. Drop all NAN records\n",
    "4. Sorteren op **person_ctry_code** en enkel EU landen\n",
    "5. **address_1 en address_2** in een csv file extracten\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">Het gedeelte in commentaar doet het zelfde maar dan met de colommen <b>street, city, zip_code.</b> Hiervoor hebben we ondervonden dat er minder ingevulde records zijn.</div>\n",
    "Windows\n",
    "<div class=\"alert alert-block alert-info\">python generate-spacy-format.py</div>\n",
    "Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 generate-spacy-format.py</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cb0ba",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0fe296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"./EU/data/samples/500ksample.pkl\")\n",
    "\n",
    "# extract_street = df.filter(items=['street', 'city', 'zip_code', 'person_ctry_code'])\n",
    "# dropstreet = extract_street.dropna()\n",
    "# filterstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# nostreet = filterstreet[filterstreet['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]\n",
    "# dropstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# newstreet = dropstreet[dropstreet['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]]\n",
    "# pf = pf.groupby(['person_ctry_code'])\n",
    "\n",
    "pf = df.filter(items=['address_1', 'address_2', 'person_ctry_code'])\n",
    "pf = pf.dropna()\n",
    "pf = pf.sort_values(by=[('person_ctry_code')])\n",
    "pf = pf[pf['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]\n",
    "result = pf.filter(items=['address_1', 'address_2','person_ctry_code'])\n",
    "\n",
    "result.to_csv('./EU/data/samples/500ksample-europefilter-address.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513261e",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2522a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"./USA/data/samples/500ksample.pkl\")\n",
    "\n",
    "#STREET CITY ZIPCODE\n",
    "# extract_street = df.filter(items=['street', 'city', 'zip_code', 'person_ctry_code'])\n",
    "# dropstreet = extract_street.dropna()\n",
    "# filterstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# nostreet = filterstreet[filterstreet['person_ctry_code'].isin(['US'])]\n",
    "# dropstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# newstreet = dropstreet[dropstreet['person_ctry_code'].isin(['US'])]]\n",
    "# pf = pf.groupby(['person_ctry_code'])\n",
    "\n",
    "#ADDRESS1 ADDRESS2\n",
    "pf = df.filter(items=['address_1', 'address_2', 'person_ctry_code'])\n",
    "pf = pf.dropna()\n",
    "pf = pf.sort_values(by=[('person_ctry_code')])\n",
    "pf = pf[pf['person_ctry_code'].isin(['US'])]\n",
    "result = pf.filter(items=['address_1', 'address_2'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result.to_csv('./USA/data/samples/500ksample-americanfilter-address.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a03a2e",
   "metadata": {},
   "source": [
    "## [Genereer_trainingdata](#Genereer_trainingdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383883c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parsing a csv file with USAropean addresses to spaCy readable format\n",
    "Dit script gaat ons trainings data bezorgen van een op voorhand gegenereerde csv file.\n",
    "Doormiddel van gebruik van regex\n",
    "<!-- > TODO: regex uitleggen -->\n",
    "Om onze trainingsdata te genereren moeten we eerst en vooral zorgen dat onze data uit de pickel file wordt ingelezen en geparset naar het correcte formaat. In ons script ```parser.py``` checken we elke entry op verschillende patronen om te bepalen of ze bruikbaar zijn.\n",
    "Eerst en vooral checken we met \n",
    "> ```(.*),(.*)``` \n",
    "\n",
    "of de string een komma bevat met ervoor en erna telkens een groep van karakters. Als de string voldoet aan deze voorwaarde splitsen we de string op in 2 groepen, groep 1 zijnde het straat-gedeelte van het adres en groep 2 zijnde het gemeente gedeelte van het adres. Vervolgens gaan we een aantal meer specifieke reguliere expressies toepassen om te verifieren of de string hier aan voldoet. \n",
    "Die eerste reguliere expressie die we gebruiken is \n",
    "> ```(^(.*) ([0-9]{3,5}-[0-9]{4}))```\n",
    "\n",
    "We passen deze toe op het gemeente-gedeelte van de originele string.\n",
    "Deze regex doet het volgende:\n",
    "* Is er een opeenvolging van eender welke karakters (groep 1)\n",
    "* volgt na deze groep 1 een spatie\n",
    "* volgt na de spatie een nieuwe groep (groep 2) bestaande uit: 3, 4 of 5 cijfers \n",
    "gevolgd door een '-' gevolgd door opnieuw 4 cijfers.\n",
    "Als deze groepen aanwezig zijn hebben we dus een string met de stad (groep 1) en een string met de postcode (groep 2).\n",
    "\n",
    "Als volgende hebben we een reguliere expressie die specifiek voor Nederland geldt:\n",
    "> ```(^([0-9]{4} [A-Z]{2}) (.*))```\n",
    "\n",
    "Deze regex matcht 2 groepen:\n",
    "groep 1:\n",
    "* 4 opeenvolgende cijfers\n",
    "* een spatie\n",
    "* 2 opeenvolgende hoofdletters\n",
    "groep 2:\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "\n",
    "Als laatste hebben we 2 reguliere expressies specifiek voor de VS, Belgie en Duitsland in 2 formaten.\n",
    "Formaat 1:\n",
    "> ```((^[0-9]{4,5}) (.*))```\n",
    "\n",
    "* 4 of 5 opeenvolgende cijfers\n",
    "* een spatie\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "Formaat 2:\n",
    "> ```(^(.*) [0-9]{4,5})```\n",
    "\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "* een spatie\n",
    "* 4 of 5 opeenvolgende cijfers\n",
    "\n",
    "<div>\n",
    "Dit script maakt een \"training_EU.py\" file in de map /data/trainingData\n",
    "</div>\n",
    "<div>\n",
    "De data komt in het formaar:\n",
    "</div>\n",
    "\n",
    "<blockquote>\n",
    "TRAININGS_DATA = [<br>\n",
    "    &emsp;(\"Heipelweg 7,A-8700 Leoben\",[(0,9, \"STREET\"),(10,11, \"NUMBER\"),(19,25, \"CITY\"),(12,18, \"ZIPCODE\")]),<br>\n",
    "    &emsp;...<br>\n",
    "    ]<br>\n",
    "</blockquote>\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python generate-spacy-format.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 generate-spacy-format.py</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee93a2",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1a9fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on street:  3060\n",
      "failed on city:  1935\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import re\n",
    "from 0 import unidecode\n",
    "\n",
    "with open('./EU/data/samples/500ksample-europefilter-address.csv', newline=\"\\n\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    counter = 0\n",
    "    f = open(\"./EU/output/fouten_generate.txt\", 'w')\n",
    "    f.close\n",
    "    f = open(\"./EU/data/validation/validation_EU.txt\", 'w')\n",
    "    f.close\n",
    "    f = open(\"./EU/data/trainingData/training_EU.py\", 'w')\n",
    "    f.write(\"TRAININGS_DATA = [\\n\")\n",
    "    f.close()\n",
    "    f = open(\"./EU/data/trainingData/dev_EU.py\", 'w')\n",
    "    f.write(\"TRAININGS_DATA = [\\n\")\n",
    "    f.close()\n",
    "    fail_numberstreet = 0\n",
    "    fail_cityzip = 0 \n",
    "    for row in csvreader:\n",
    "        correct = True\n",
    "        adres = row[0] + ',' + row[1]\n",
    "        adres = unidecode(adres)\n",
    "        if not re.match(\".*,.*,.*\", adres):\n",
    "            adreslengte = len(adres)\n",
    "            adres1 = row[0]\n",
    "            totale_lengte_straat = len(adres1) + 1\n",
    "            adres2 = row[1]\n",
    "            # nummer + straat\n",
    "            if re.match('^([0-9\\-]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+)', adres1):\n",
    "                split = re.search('^([0-9\\-]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+)', adres1)\n",
    "                straat = split.span(3)\n",
    "                nummer = split.span(1)\n",
    "\n",
    "            # straat + nummer\n",
    "            elif re.match('^([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+) ([0-9\\/\\-]+( ?[a-zA-Z]*)?)', adres1):\n",
    "                split = re.search('^([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+) ([0-9\\/\\-]+( ?[a-zA-Z]*)?)', adres1)\n",
    "                straat = split.span(1)\n",
    "                nummer = split.span(2)\n",
    "            else:\n",
    "                f = open(\"./EU/output/fouten_generate.txt\", 'a')\n",
    "                f.write(\"street: \" + adres + \"\\n\")\n",
    "                f.close()\n",
    "                fail_numberstreet +=1\n",
    "                correct = False\n",
    "            \n",
    "            # zipcode + city\n",
    "            if re.match('([ A-Z-]*[0-9]+( ?[A-Z]{2})?) ?([\\u00C0-\\u0338a-zA-Z ./-]+)$', adres2):\n",
    "                split = re.search('([ A-Z-]*[0-9]+( ?[A-Z]{2})?) ?([\\u00C0-\\u0338a-zA-Z ./-]+)$', adres2)\n",
    "                zipcode = list(split.span(1))\n",
    "                city = list(split.span(3))\n",
    "                zipcode[0] += totale_lengte_straat\n",
    "                zipcode[1] += totale_lengte_straat\n",
    "                city[0] += totale_lengte_straat\n",
    "                city[1] += totale_lengte_straat\n",
    "\n",
    "            # city + zipcode \n",
    "            elif re.match('([\\u00C0-\\u017Fa-zA-Z ./-]+) ?([ A-Z-]*[0-9]+)$', adres2):\n",
    "                split = re.search('([\\u00C0-\\u017Fa-zA-Z ./-]+) ?([ A-Z-]*[0-9]+)$', adres2)\n",
    "                zipcode = list(split.span(2))\n",
    "                city = list(split.span(1))\n",
    "                zipcode[0] += totale_lengte_straat\n",
    "                zipcode[1] += totale_lengte_straat\n",
    "                city[0] += totale_lengte_straat\n",
    "                city[1] += totale_lengte_straat\n",
    "            else:\n",
    "                f = open(\"./EU/output/fouten_generate.txt\", 'a')\n",
    "                f.write(\"city: \" + adres + \"\\n\")\n",
    "                f.close()\n",
    "                fail_cityzip += 1\n",
    "                correct = False\n",
    "\n",
    "            if correct:\n",
    "                counter += 1\n",
    "                if counter < 5:\n",
    "                    f = open(\"./EU/data/trainingData/training_EU.py\", 'a')\n",
    "                    f.write(\"\\t(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straat[0])+\",\"+str(straat[1])+\", \\\"STREET\\\"),(\"+str(nummer[0])+\",\"+str(nummer[1])+\", \\\"NUMBER\\\"),(\"+str(city[0])+\",\"+str(city[1])+\", \\\"CITY\\\"),(\"+str(zipcode[0])+\",\"+str(zipcode[1])+\", \\\"ZIPCODE\\\")]),\\n\")\n",
    "                    f.close()\n",
    "                else:\n",
    "                    f = open(\"./EU/data/trainingData/dev_EU.py\", 'a')\n",
    "                    f.write(\"\\t(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straat[0])+\",\"+str(straat[1])+\", \\\"STREET\\\"),(\"+str(nummer[0])+\",\"+str(nummer[1])+\", \\\"NUMBER\\\"),(\"+str(city[0])+\",\"+str(city[1])+\", \\\"CITY\\\"),(\"+str(zipcode[0])+\",\"+str(zipcode[1])+\", \\\"ZIPCODE\\\")]),\\n\")\n",
    "                    f.close()\n",
    "                    counter = 0\n",
    "                f = open(\"./EU/data/validation/validation_EU.txt\", 'a')\n",
    "                f.write(adres+\"&\"+str(straat[0])+\";\"+str(straat[1])+\";STREET&\"+str(nummer[0])+\";\"+str(nummer[1])+\";NUMBER&\"+str(city[0])+\";\"+str(city[1])+\";CITY&\"+str(zipcode[0])+\";\"+str(zipcode[1])+\";ZIPCODE\\n\")\n",
    "                f.close()\n",
    "            # print(\"(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straatposbegin)+\",\"+str(straatposeind)+\", \\\"STREET\\\"),(\"+str(nummerposbegin)+\",\"+str(nummerposeind)+\", \\\"NUMBER\\\"),(\"+str(cityposbegin)+\",\"+str(cityposeind)+\", \\\"CITY\\\"),(\"+str(zipcodeposbegin)+\",\"+str(zipcodeposeind)+\", \\\"ZIPCODE\\\")])\")\n",
    "    f = open(\"./EU/data/trainingData/training_EU.py\", \"a\")\n",
    "    f.write(\"]\")\n",
    "    f.close()\n",
    "    f = open(\"./EU/data/trainingData/dev_EU.py\", \"a\")\n",
    "    f.write(\"]\")\n",
    "    f.close()\n",
    "    print(\"failed on street: \", fail_numberstreet)\n",
    "    print(\"failed on city: \", fail_cityzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cef1f5",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3b2aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on street:  251\n",
      "failed on number:  2376\n",
      "failed on city:  2320\n",
      "failed on zipcode:  68\n",
      "failed on state:  87\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "def fout(element,adres, fails):\n",
    "    f = open(\"./USA/output/fouten_generate.txt\", 'a')\n",
    "    f.write(element + \": \" + adres + \"\\n\")\n",
    "    f.close()\n",
    "    return fails + 1\n",
    "\n",
    "with open('./USA/data/samples/500ksample-americanfilter-address.csv', newline=\"\\n\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    counter = 0 \n",
    "    f = open(\"./USA/output/fouten_generate.txt\", 'w')\n",
    "    f.close\n",
    "    f = open(\"./USA/data/trainingData/training_USA.py\", 'w')\n",
    "    f.write(\"TRAININGS_DATA = [\\n\")\n",
    "    f.close()\n",
    "    f = open(\"./USA/data/trainingData/dev_USA.py\", 'w')\n",
    "    f.write(\"TRAININGS_DATA = [\\n\")\n",
    "    f.close()\n",
    "    f = open(\"./USA/data/validation/validation_USA.txt\", 'w')\n",
    "    f.close\n",
    "    fail_nummer = 0\n",
    "    fail_straat = 0\n",
    "    fail_city = 0\n",
    "    fail_zipcode = 0\n",
    "    fail_state = 0\n",
    "    counter = 0\n",
    "    nummmer = \"\"\n",
    "    straat = \"\"\n",
    "    city = \"\"\n",
    "    zipcode = \"\"\n",
    "    state = \"\"\n",
    "    for row in csvreader:\n",
    "        correct = False\n",
    "        adres = ','.join(row)\n",
    "        adres = unidecode(adres)\n",
    "        adres1 = row[0]\n",
    "        adres2 = row[1]\n",
    "        totale_lengte_straat = len(adres1) + 1\n",
    "        full_string = \"\\t(\\\"\"+adres+\"\\\",\"+\"[\"\n",
    "        #nummer\n",
    "        if re.match('(/ )?([0-9]+)', adres1):\n",
    "            nummer = re.search('(/ )?([0-9]+)', adres1).span(2)\n",
    "            full_string += \"(\"+str(nummer[0])+\",\"+str(nummer[1])+\", \\\"NUMBER\\\"),\"\n",
    "            correct = True\n",
    "        else:\n",
    "            fail_nummer = fout(\"Nummer\", adres1, fail_nummer)\n",
    "            continue\n",
    "        #straat\n",
    "        if re.search('[0-9]+ ([\\s\\S]*)$', adres1):\n",
    "            straat = re.search('[0-9]+ ([\\s\\S]*)$', adres1).span(1)\n",
    "            full_string += \"(\"+str(straat[0])+\",\"+str(straat[1])+\", \\\"STREET\\\"),\"\n",
    "            correct = True\n",
    "        else:\n",
    "            fail_straat = fout(\"Straat\", adres1, fail_straat)\n",
    "            continue\n",
    "        # if not re.match('([0-9]+)', adres1) and not re.match('[0-9]+ ([\\s\\S]*)$', adres1):\n",
    "            \n",
    "        #city\n",
    "        if re.match('([a-zA-Z ]+?(?=,))', adres2):\n",
    "            city = re.search('([a-zA-Z ]+?(?=,))', adres2).span(1)\n",
    "            city = list(city)\n",
    "            city[0] += totale_lengte_straat\n",
    "            city[1] += totale_lengte_straat\n",
    "            full_string += \"(\"+str(city[0])+\",\"+str(city[1])+\", \\\"CITY\\\"),\"\n",
    "            correct = True\n",
    "        else:\n",
    "            fail_city = fout(\"City\", adres2, fail_city)\n",
    "            continue\n",
    "        #zipcode\n",
    "        if re.search('([0-9\\-]+$)', adres2):\n",
    "            zipcode = re.search('([0-9\\-]+$)', adres2).span(1)\n",
    "            zipcode = list(zipcode)\n",
    "            zipcode[0] += totale_lengte_straat\n",
    "            zipcode[1] += totale_lengte_straat\n",
    "            full_string += \"(\"+str(zipcode[0])+\",\"+str(zipcode[1])+\", \\\"ZIPCODE\\\"),\"\n",
    "            correct = True\n",
    "        else:\n",
    "            fail_zipcode = fout(\"Zipcode\", adres2, fail_zipcode)\n",
    "            continue\n",
    "        #state\n",
    "        if re.search('(,? )([ A-Za-z]*)(?<! ),? [0-9]', adres2):\n",
    "            state = re.search('(,? )([ A-Za-z]*)(?<! ),? [0-9]', adres2).span(2)\n",
    "            state = list(state)\n",
    "            state[0] += totale_lengte_straat\n",
    "            state[1] += totale_lengte_straat\n",
    "            if not city[1] >= state[0]:\n",
    "                full_string += \"(\"+ str(state[0])+\",\"+str(state[1])+\", \\\"STATE\\\")\"\n",
    "                correct = True\n",
    "        else:\n",
    "            fail_state = fout(\"State\", adres2, fail_state)\n",
    "            continue    \n",
    "\n",
    "        if correct:\n",
    "            counter += 1\n",
    "            if counter < 5:\n",
    "                f = open(\"./USA/data/trainingData/training_USA.py\", 'a')\n",
    "                f.write(full_string + \"]),\\n\")\n",
    "                f.close()\n",
    "            else:\n",
    "                f = open(\"./USA/data/trainingData/dev_USA.py\", 'a')\n",
    "                f.write(full_string + \"]),\\n\")\n",
    "                f.close()\n",
    "                counter = 0\n",
    "            f = open(\"./USA/data/validation/validation_USA.txt\", 'a')\n",
    "            f.write(adres+\"&\"+str(straat[0])+\";\"+str(straat[1])+\";STREET&\"+str(nummer[0])+\";\"+str(nummer[1])+\";NUMBER&\"+str(city[0])+\";\"+str(city[1])+\";CITY&\"+str(zipcode[0])+\";\"+str(zipcode[1])+\";ZIPCODE&\"+str(state[0])+\";\"+str(state[1])+\";STATE\\n\")\n",
    "            f.close()\n",
    "            # print(\"(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straatposbegin)+\",\"+str(straatposeind)+\", \\\"STREET\\\"),(\"+str(nummerposbegin)+\",\"+str(nummerposeind)+\", \\\"NUMBER\\\"),(\"+str(cityposbegin)+\",\"+str(cityposeind)+\", \\\"CITY\\\"),(\"+str(zipcodeposbegin)+\",\"+str(zipcodeposeind)+\", \\\"ZIPCODE\\\")])\")\n",
    "    f = open(\"./USA/data/trainingData/training_USA.py\", \"a\")\n",
    "    f.write(\"]\")\n",
    "    f.close()\n",
    "    f = open(\"./USA/data/trainingData/dev_USA.py\", \"a\")\n",
    "    f.write(\"]\")\n",
    "    f.close()\n",
    "    print(\"failed on street: \", fail_straat)\n",
    "    print(\"failed on number: \", fail_nummer)\n",
    "    print(\"failed on city: \", fail_city)\n",
    "    print(\"failed on zipcode: \", fail_zipcode)\n",
    "    print(\"failed on state: \", fail_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60493d9",
   "metadata": {},
   "source": [
    "## [Prepare_binarydata](#Prepare_binarydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d66c1",
   "metadata": {},
   "source": [
    "In geval van Europa wordt de \"/EU/data/trainingData/training_EU.py\" file omgezet naar binaire data. <br>\n",
    "Dit wordt dan in de map \"/EU/data/binaryData/\" als spacy file aangemaakt. De \"train.spacy\" is de data dat gebruikt wordt als training. Dit is 80% van de totale gegenereerde trainingsdata <br>\n",
    "\"dev.spacy\" is de validatiedata dat gebruikt wordt bij het trainen van het model. Dit is de resterende 20% van de totale trainingsdata.\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python PrepareData.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 PrepareData.py</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da609486",
   "metadata": {},
   "source": [
    "### PrepareData.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629668f",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390a1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "from spacy.tokens import DocBin\n",
    "sys.path.insert(0, './EU/data/trainingData')\n",
    "from training_EU import TRAININGS_DATA as TD\n",
    "\n",
    "f = open(\"./EU/output/problems.txt\", 'w')\n",
    "f.close()\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            f = open(\"./EU/output/problems.txt\", 'a')\n",
    "            f.write(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\\n\")\n",
    "            f.close()\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./EU/data/binaryData/train.spacy\")\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./EU/data/binaryData/dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce80039",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75c096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "from spacy.tokens import DocBin\n",
    "sys.path.insert(0, './USA/data/trainingData')\n",
    "from training_USA import TRAININGS_DATA as TD\n",
    "from dev_USA import TRAININGS_DATA as DD\n",
    "\n",
    "f = open(\"./USA/output/fouten_dataprepare.txt\", 'w')\n",
    "f.close()\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            f = open(\"./USA/output/fouten_dataprepare.txt\", 'a')\n",
    "            f.write(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\\n\")\n",
    "            f.close()\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./USA/data/binaryData/train.spacy\")\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in DD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./USA/data/binaryData/dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e862d",
   "metadata": {},
   "source": [
    "## [Start_training](#Start_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0281e3",
   "metadata": {},
   "source": [
    "Hier komt het moment waar we kunnen beginnen met trainen van het model. Dit gebeurt via de command line. <br>\n",
    "De spacy train geeft aan dat we de training starten. Vervolgens wordt de config file meegegeven. Bij het \"--output\" argument staat de locatie waar we het model opslaan. In deze map komt het best gevonden model en het laatste aangemaakte model.<br>\n",
    "\n",
    "Tokenization is een proces waarbij er tekst word onderverdeeld in verschillende segmenten, deze segmenten worden tokens genoemd. Dus eerst ‘tokenizeert’ spaCy jouw tekst in meerdere segmenten. Deze segmenten worden bepaald op basis van woorden, punctuatie (bijvoorbeeld aan het einde van een zin). Zo moet je uitkijken want U.K. bijvoorbeeld moet gezien worden als 1 token.\n",
    "\n",
    "We maakten gebruik van tokenizers omdat de komma’s in onze dataset een probleem waren. Blijkbaar werden komma’s gezien door SpaCy als een ingebouwde symbool, dus getallen tussen een komma werden gezien als een double, terwijl dit integers moesten voorstellen.\n",
    "Eerst wouden we alle komma’s vervangen door een punt komma of door een spatie, maar dit gaf nog steeds problemen. Met behulp van tokenization konden we de komma zien als een eigen ‘token’ en werden de integers niet meer beschouwd als een double.\n",
    "> Het adres  \"Wagramer Strasse 17,1220 Vienna\" was dus een probleem, aangezien het straatnummer 17 en postcode 1220 niet werden gezien als twee integers, maar als een double. \n",
     "\n",
    "> voorbeeld van hoe een tokenizer een adres opdeelt in meerdere segmenten: "\n",
 \"Am Kirchwald 347,6100 Seefeld\" => \"Am\"; \"Kirchwald\"; \"347\"; \",\"; \"6100\"; \"Seefeld\"\n",
    "\n",
  
  "https://spacy.io/api/tokenizer"\n",
  "https://spacy.io/usage/linguistic-features#how-tokenizer-works"\n",

    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python TrainModel.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 TrainModel.py</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecaf75f",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7d791",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59febd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-07 16:48:54,004] [INFO] Set up nlp object from config\n",
      "[2022-03-07 16:48:54,014] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-03-07 16:48:54,134] [INFO] Created vocabulary\n",
      "[2022-03-07 16:48:54,135] [INFO] Finished initializing nlp object\n",
      "[2022-03-07 16:48:58,669] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: EU/model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "Ik heb een rode patat\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     79.00    9.64    7.61   13.13    0.10\n",
      "  0     200        159.82   4118.32   95.98   93.66   98.42    0.96\n",
      "  1     400        139.52   1930.88   96.68   94.28   99.21    0.97\n",
      "  2     600        168.12   2149.74   97.77   96.58   98.98    0.98\n",
      "  3     800        213.61   1766.20   98.45   97.75   99.15    0.98\n",
      "  4    1000        213.62   1276.51   98.82   98.54   99.10    0.99\n",
      "  5    1200        220.16   1183.02   99.15   99.54   98.77    0.99\n",
      "  7    1400        219.21    894.81   99.47   99.58   99.36    0.99\n",
      "  9    1600        276.28    651.26   99.60   99.81   99.39    1.00\n",
      " 12    1800        301.56    555.96   99.59   99.75   99.42    1.00\n",
      " 15    2000        408.10    524.16   99.64   99.89   99.40    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "EU/model/model-last\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python3 -m spacy train config_EU.cfg --output ./EU/model --code ./EU/config/CustomTokenizer.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4283f",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c743218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-07 16:52:48,526] [INFO] Set up nlp object from config\n",
      "[2022-03-07 16:52:48,536] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-03-07 16:52:48,660] [INFO] Created vocabulary\n",
      "[2022-03-07 16:52:48,661] [INFO] Finished initializing nlp object\n",
      "[2022-03-07 16:52:53,409] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: USA/model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "Ik heb een rode patat\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     72.50   13.97   10.74   19.99    0.14\n",
      "  0     200        119.18   2649.55   99.25   99.06   99.43    0.99\n",
      "  0     400        128.43    281.56   99.40   99.23   99.57    0.99\n",
      "  1     600        135.12    194.39   99.57   99.48   99.66    1.00\n",
      "  2     800        266.25    227.30   99.61   99.50   99.72    1.00\n",
      "  2    1000        205.38    156.96   99.65   99.56   99.74    1.00\n",
      "  3    1200        311.72    176.16   99.52   99.41   99.63    1.00\n",
      "  5    1400        290.19    129.04   99.58   99.47   99.70    1.00\n",
      "  6    1600        386.24    141.16   99.65   99.56   99.75    1.00\n",
      "  8    1800        339.43    128.25   99.61   99.52   99.70    1.00\n",
      " 10    2000        354.31    115.26   99.58   99.50   99.66    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "USA/model/model-last\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python3 -m spacy train config_USA.cfg --output ./USA/model --code ./USA/config/CustomTokenizer.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbe897",
   "metadata": {},
   "source": [
    "## [Recall_And_Precision_plus_Visualiseer_model](#Recall_And_Precision_plus_Visualiseer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f001181",
   "metadata": {},
   "source": [
    "In volgende code kan u een visueel beeld krijgen van uitkomsten die het model heeft gevonden.<br>\n",
    "Dit kan gedaan worden door een csv file mee te geven. Of door zelf adressen in te geven in de list die momenteel in commentaar staat. <br>\n",
    "Erna wordt het model gekozen hier hebt u de keuze uit het beste model of het laatste model.\n",
    "<div>nlp = spacy.load(\"./model/model-best\") of<br>\n",
    "nlp = spacy.load(\"./model/model-last\")</div>\n",
    "\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python TestModel.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 TestModel.py</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">We hebben de laatste 3 regels in commentaar geplaatst zodat de output van de Jupyter notebook niet te lang werd. We raden aan om het commando in terminal uit te voeren als u de volledige uitkomst wilt bekijken. U kan het resultaat bekijken door naar de link <a href=\"http://localhost:5000\">http://localhost:5000</a> te gaan.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03ca51",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1457b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "straat: 0 percentage: 0.0%\n",
      "nummer: 0 percentage: 0.0%\n",
      "city: 0 percentage: 0.0%\n",
      "zipcode: 0 percentage: 0.0%\n",
      "counter: 1\n",
      "----------------------person_ctry_code--------------------------------\n",
      "straat: 1 percentage: 100.0%\n",
      "nummer: 1 percentage: 100.0%\n",
      "city: 1 percentage: 100.0%\n",
      "zipcode: 1 percentage: 100.0%\n",
      "counter: 1\n",
      "----------------------AT--------------------------------\n",
      "straat: 264 percentage: 67.00507614213198%\n",
      "nummer: 259 percentage: 65.73604060913706%\n",
      "city: 260 percentage: 65.98984771573603%\n",
      "zipcode: 263 percentage: 66.75126903553299%\n",
      "counter: 394\n",
      "----------------------BE--------------------------------\n",
      "straat: 263 percentage: 55.838641188959656%\n",
      "nummer: 259 percentage: 54.989384288747345%\n",
      "city: 254 percentage: 53.92781316348195%\n",
      "zipcode: 258 percentage: 54.77707006369427%\n",
      "counter: 471\n",
      "----------------------BG--------------------------------\n",
      "straat: 0 percentage: 0.0%\n",
      "nummer: 0 percentage: 0.0%\n",
      "city: 0 percentage: 0.0%\n",
      "zipcode: 0 percentage: 0.0%\n",
      "counter: 6\n",
      "----------------------CY--------------------------------\n",
      "straat: 4 percentage: 50.0%\n",
      "nummer: 3 percentage: 37.5%\n",
      "city: 2 percentage: 25.0%\n",
      "zipcode: 4 percentage: 50.0%\n",
      "counter: 8\n",
      "----------------------CZ--------------------------------\n",
      "straat: 16 percentage: 25.806451612903224%\n",
      "nummer: 16 percentage: 25.806451612903224%\n",
      "city: 15 percentage: 24.193548387096776%\n",
      "zipcode: 15 percentage: 24.193548387096776%\n",
      "counter: 62\n",
      "----------------------DE--------------------------------\n",
      "straat: 2957 percentage: 49.242298084929224%\n",
      "nummer: 2937 percentage: 48.90924229808493%\n",
      "city: 2929 percentage: 48.77601998334721%\n",
      "zipcode: 2942 percentage: 48.992506244796004%\n",
      "counter: 6005\n",
      "----------------------DK--------------------------------\n",
      "straat: 176 percentage: 43.24324324324324%\n",
      "nummer: 166 percentage: 40.78624078624078%\n",
      "city: 170 percentage: 41.76904176904177%\n",
      "zipcode: 175 percentage: 42.997542997543%\n",
      "counter: 407\n",
      "----------------------EE--------------------------------\n",
      "straat: 4 percentage: 36.36363636363637%\n",
      "nummer: 3 percentage: 27.27272727272727%\n",
      "city: 4 percentage: 36.36363636363637%\n",
      "zipcode: 4 percentage: 36.36363636363637%\n",
      "counter: 11\n",
      "----------------------ES--------------------------------\n",
      "straat: 34 percentage: 5.287713841368585%\n",
      "nummer: 27 percentage: 4.199066874027993%\n",
      "city: 31 percentage: 4.821150855365474%\n",
      "zipcode: 33 percentage: 5.132192846034215%\n",
      "counter: 643\n",
      "----------------------FI--------------------------------\n",
      "straat: 206 percentage: 53.5064935064935%\n",
      "nummer: 199 percentage: 51.688311688311686%\n",
      "city: 202 percentage: 52.467532467532465%\n",
      "zipcode: 203 percentage: 52.72727272727272%\n",
      "counter: 385\n",
      "----------------------FR--------------------------------\n",
      "straat: 747 percentage: 24.743292480953958%\n",
      "nummer: 777 percentage: 25.736999006293477%\n",
      "city: 707 percentage: 23.41835044716794%\n",
      "zipcode: 719 percentage: 23.815833057303742%\n",
      "counter: 3019\n",
      "----------------------GR--------------------------------\n",
      "straat: 12 percentage: 31.57894736842105%\n",
      "nummer: 13 percentage: 34.21052631578947%\n",
      "city: 11 percentage: 28.947368421052634%\n",
      "zipcode: 13 percentage: 34.21052631578947%\n",
      "counter: 38\n",
      "----------------------HR--------------------------------\n",
      "straat: 4 percentage: 80.0%\n",
      "nummer: 4 percentage: 80.0%\n",
      "city: 4 percentage: 80.0%\n",
      "zipcode: 4 percentage: 80.0%\n",
      "counter: 5\n",
      "----------------------HU--------------------------------\n",
      "straat: 15 percentage: 15.463917525773196%\n",
      "nummer: 14 percentage: 14.432989690721648%\n",
      "city: 16 percentage: 16.49484536082474%\n",
      "zipcode: 17 percentage: 17.525773195876287%\n",
      "counter: 97\n",
      "----------------------IE--------------------------------\n",
      "straat: 8 percentage: 4.848484848484849%\n",
      "nummer: 8 percentage: 4.848484848484849%\n",
      "city: 0 percentage: 0.0%\n",
      "zipcode: 8 percentage: 4.848484848484849%\n",
      "counter: 165\n",
      "----------------------IT--------------------------------\n",
      "straat: 250 percentage: 17.5561797752809%\n",
      "nummer: 246 percentage: 17.275280898876407%\n",
      "city: 237 percentage: 16.64325842696629%\n",
      "zipcode: 243 percentage: 17.064606741573034%\n",
      "counter: 1424\n",
      "----------------------LT--------------------------------\n",
      "straat: 1 percentage: 25.0%\n",
      "nummer: 1 percentage: 25.0%\n",
      "city: 1 percentage: 25.0%\n",
      "zipcode: 1 percentage: 25.0%\n",
      "counter: 4\n",
      "----------------------LU--------------------------------\n",
      "straat: 11 percentage: 35.483870967741936%\n",
      "nummer: 11 percentage: 35.483870967741936%\n",
      "city: 11 percentage: 35.483870967741936%\n",
      "zipcode: 11 percentage: 35.483870967741936%\n",
      "counter: 31\n",
      "----------------------LV--------------------------------\n",
      "straat: 5 percentage: 62.5%\n",
      "nummer: 4 percentage: 50.0%\n",
      "city: 4 percentage: 50.0%\n",
      "zipcode: 5 percentage: 62.5%\n",
      "counter: 8\n",
      "----------------------MT--------------------------------\n",
      "straat: 1 percentage: 33.33333333333333%\n",
      "nummer: 1 percentage: 33.33333333333333%\n",
      "city: 1 percentage: 33.33333333333333%\n",
      "zipcode: 1 percentage: 33.33333333333333%\n",
      "counter: 3\n",
      "----------------------NL--------------------------------\n",
      "straat: 1186 percentage: 98.26014913007457%\n",
      "nummer: 1184 percentage: 98.09444904722451%\n",
      "city: 1059 percentage: 87.73819386909693%\n",
      "zipcode: 1187 percentage: 98.34299917149959%\n",
      "counter: 1207\n",
      "----------------------PT--------------------------------\n",
      "straat: 1 percentage: 1.639344262295082%\n",
      "nummer: 1 percentage: 1.639344262295082%\n",
      "city: 1 percentage: 1.639344262295082%\n",
      "zipcode: 1 percentage: 1.639344262295082%\n",
      "counter: 61\n",
      "----------------------RO--------------------------------\n",
      "straat: 0 percentage: 0.0%\n",
      "nummer: 0 percentage: 0.0%\n",
      "city: 0 percentage: 0.0%\n",
      "zipcode: 0 percentage: 0.0%\n",
      "counter: 14\n",
      "----------------------SE--------------------------------\n",
      "straat: 17 percentage: 2.380952380952381%\n",
      "nummer: 17 percentage: 2.380952380952381%\n",
      "city: 14 percentage: 1.9607843137254901%\n",
      "zipcode: 16 percentage: 2.2408963585434174%\n",
      "counter: 714\n",
      "----------------------SI--------------------------------\n",
      "straat: 19 percentage: 79.16666666666666%\n",
      "nummer: 19 percentage: 79.16666666666666%\n",
      "city: 18 percentage: 75.0%\n",
      "zipcode: 18 percentage: 75.0%\n",
      "counter: 24\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from curses.ascii import ctrl\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "# test_text = [\"Keilalahdentie 4,02150 Espoo\", \"Weisshsusstrasse 2,52066 Aachen\", \"14 rue Royale,75008 Paris\", \"Hüninger Strasse 25,14195 Berlin\", \"19 bis rue Hoche,49100 Angers\"]\n",
    "test_text = []\n",
    "with open('./EU/data/samples/500ksample-europefilter-address.csv', newline=\"\\n\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        row = (row[0] + ',' + row[1],row[2])\n",
    "        # print(row)\n",
    "        test_text.append(row)\n",
    "\n",
    "labeledData = open('./EU/data/validation/validation_EU.txt', 'r')\n",
    "adreslist = []\n",
    "for line in labeledData.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    line = line.split(\"&\")\n",
    "    record = []\n",
    "    recordtuple = (line[0],record)\n",
    "    for i in line:\n",
    "        i = i.split(\";\")\n",
    "        record.append(i)\n",
    "    record.pop(0)\n",
    "    adreslist.append(recordtuple)\n",
    "\n",
    "nlp = spacy.load(\"./EU/model/model-best\")\n",
    "# nlp = spacy.load(\"./EU/model/model-last\")\n",
    "lijst = []\n",
    "correct_counter = 0\n",
    "total_counter = 0\n",
    "total_counter_straat = 0\n",
    "total_counter_nummer = 0\n",
    "total_counter_city = 0\n",
    "total_counter_zipcode = 0\n",
    "ctry_code = \"\"\n",
    "for i in test_text:\n",
    "    adres_ctry_code = i[1]\n",
    "    # print(adres_ctry_code)\n",
    "    # print(i[0])\n",
    "    doc = nlp(i[0])\n",
    "    ents = list(doc.ents)\n",
    "    for at in adreslist:\n",
    "        if at[0] == str(doc):\n",
    "            for j in at[1]:\n",
    "                for token in ents:\n",
    "                    # print(token)\n",
    "                    bool1 = str(j[0]) == str(token.start_char)\n",
    "                    bool2 = str(j[1]) == str(token.end_char)\n",
    "                    bool3 = j[2] == token.label_\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STREET\":\n",
    "                        total_counter_straat +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"NUMBER\":\n",
    "                        total_counter_nummer +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"CITY\":\n",
    "                        total_counter_city +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"ZIPCODE\":\n",
    "                        total_counter_zipcode +=1\n",
    "    lijst.append(doc)\n",
    "    total_counter += 1\n",
    "    if ctry_code != adres_ctry_code:\n",
    "        print(\"----------------------\" + ctry_code + \"--------------------------------\")\n",
    "        print(\"straat: \" + str(total_counter_straat) + \" percentage: \" + str(total_counter_straat / total_counter * 100)+ \"%\")\n",
    "        print(\"nummer: \" + str(total_counter_nummer) + \" percentage: \" + str(total_counter_nummer / total_counter * 100)+ \"%\")\n",
    "        print(\"city: \" + str(total_counter_city) + \" percentage: \" + str(total_counter_city / total_counter * 100)+ \"%\")\n",
    "        print(\"zipcode: \" + str(total_counter_zipcode) + \" percentage: \" + str(total_counter_zipcode / total_counter * 100)+ \"%\")\n",
    "        print(\"counter: \" + str(total_counter))\n",
    "        ctry_code = adres_ctry_code\n",
    "        total_counter = 0\n",
    "        total_counter_straat = 0\n",
    "        total_counter_nummer = 0\n",
    "        total_counter_city = 0\n",
    "        total_counter_zipcode = 0\n",
    "\n",
    "\n",
    "\n",
    "# colors = {\"STREET\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"NUMBER\": \"linear-gradient(90deg, #3f5efb, #fc466b)\", \"ZIPCODE\": \"linear-gradient(90deg, #090979, #00d4ff)\", \"CITY\": \"linear-gradient(90deg, #eeaeca, #94bbe9)\", \"OTHER\": \"linear-gradient(90deg, #22c1c3, #fdbb2d)\",}\n",
    "# options = {\"ents\": [\"CITY\", \"STREET\", \"NUMBER\", \"ZIPCODE\", \"OTHER\"], \"colors\": colors}\n",
    "# displacy.serve(lijst, style=\"ent\", options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689e304",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c7ebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straat: 9992 percentage: 99.80023971234519%\n",
      "nummer: 10000 percentage: 99.88014382740711%\n",
      "city: 10007 percentage: 99.9500599280863%\n",
      "zipzode: 10009 percentage: 99.97003595685177%\n",
      "state: 9993 percentage: 99.81022772672793%\n",
      "adress in list: 13047\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "# test_text = [\"Keilalahdentie 4,02150 Espoo\", \"Weisshsusstrasse 2,52066 Aachen\", \"14 rue Royale,75008 Paris\", \"Hüninger Strasse 25,14195 Berlin\", \"19 bis rue Hoche,49100 Angers\"]\n",
    "test_text = []\n",
    "with open('./USA/data/samples/500ksample-americanfilter-address.csv', newline=\"\\n\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in csvreader:\n",
    "        row = ','.join(row)\n",
    "        test_text.append(row)\n",
    "\n",
    "labeledData = open('./USA/data/validation/validation_USA.txt', 'r')\n",
    "adreslist = []\n",
    "for line in labeledData.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    line = line.split(\"&\")\n",
    "    record = []\n",
    "    recordtuple = (line[0],record)\n",
    "    for i in line:\n",
    "        i = i.split(\";\")\n",
    "        record.append(i)\n",
    "        # print(record)\n",
    "    record.pop(0)\n",
    "    adreslist.append(recordtuple)\n",
    "\n",
    "nlp = spacy.load(\"./USA/model/model-best\")\n",
    "# nlp = spacy.load(\"./USA/model/model-last\")\n",
    "lijst = []\n",
    "correct_counter = 0\n",
    "total_counter = 0\n",
    "total_correct_straat = 0\n",
    "total_correct_nummer = 0\n",
    "total_correct_city = 0\n",
    "total_correct_zipcode = 0\n",
    "total_correct_state = 0\n",
    "\n",
    "total_straat = 0\n",
    "total_nummer = 0\n",
    "total_city = 0\n",
    "total_zipcode = 0\n",
    "total_state = 0\n",
    "\n",
    "for i in test_text:    \n",
    "    doc = nlp(i)\n",
    "    ents = list(doc.ents)\n",
    "    for at in adreslist:\n",
    "        if at[0] == str(doc):\n",
    "            for j in at[1]:\n",
    "                for token in ents:\n",
    "                    # print(token)\n",
    "                    bool1 = str(j[0]) == str(token.start_char)\n",
    "                    bool2 = str(j[1]) == str(token.end_char)\n",
    "                    bool3 = j[2] == token.label_\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STREET\":\n",
    "                        total_correct_straat +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"NUMBER\":\n",
    "                        total_correct_nummer +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"CITY\":\n",
    "                        total_correct_city +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"ZIPCODE\":\n",
    "                        total_correct_zipcode +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STATE\":\n",
    "                        total_correct_state +=1\n",
    "                if j[2] == \"STREET\":\n",
    "                    total_straat += 1\n",
    "                if j[2] == \"NUMBER\":\n",
    "                    total_nummer += 1\n",
    "                if j[2] == \"CITY\":\n",
    "                    total_city += 1\n",
    "                if j[2] == \"ZIPCODE\":\n",
    "                    total_zipcode += 1\n",
    "                if j[2] == \"STATE\":\n",
    "                    total_state += 1\n",
    "    lijst.append(doc)\n",
    "    total_counter += 1\n",
    "print(\"straat: \" + str(total_correct_straat) + \" percentage: \" + str(total_correct_straat / total_straat * 100)+ \"%\")\n",
    "print(\"nummer: \" + str(total_correct_nummer) + \" percentage: \" + str(total_correct_nummer / total_nummer * 100)+ \"%\")\n",
    "print(\"city: \" + str(total_correct_city) + \" percentage: \" + str(total_correct_city / total_city * 100)+ \"%\")\n",
    "print(\"zipzode: \" + str(total_correct_zipcode) + \" percentage: \" + str(total_correct_zipcode / total_zipcode * 100)+ \"%\")\n",
    "print(\"state: \" + str(total_correct_state) + \" percentage: \" + str(total_correct_state / total_state * 100)+ \"%\")\n",
    "print(\"adress in list: \" + str(total_counter))\n",
    "\n",
    "# colors = {\"STREET\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"NUMBER\": \"linear-gradient(90deg, #3f5efb, #fc466b)\", \"ZIPCODE\": \"linear-gradient(90deg, #090979, #00d4ff)\", \"CITY\": \"linear-gradient(90deg, #eeaeca, #94bbe9)\", \"STATE\": \"linear-gradient(90deg, #22c1c3, #fdbb2d)\",}\n",
    "# options = {\"ents\": [\"CITY\", \"STREET\", \"NUMBER\", \"ZIPCODE\", \"STATE\"], \"colors\": colors}\n",
    "# displacy.serve(lijst, style=\"ent\", options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd94cc8-5edb-4b54-9c93-16aac9eea3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
