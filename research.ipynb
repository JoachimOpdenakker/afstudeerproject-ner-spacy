{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bc159a",
   "metadata": {},
   "source": [
    "# Progress file for NER training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e075a",
   "metadata": {},
   "source": [
    "## [Installatie](#Installatie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ec817",
   "metadata": {},
   "source": [
    "### Installeer spacy in jupyter notebook env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c28127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/wolti/.local/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (52.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/wolti/.local/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/wolti/.local/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/wolti/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wolti/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wolti/.local/lib/python3.9/site-packages (from jinja2->spacy) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unicode in /home/wolti/.local/lib/python3.9/site-packages (2.8)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m pip install unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ec813",
   "metadata": {},
   "source": [
    "### Installeer spacy voor windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d46cc",
   "metadata": {},
   "source": [
    "1. Installeer anaconda\n",
    "    <div>Dit geeft een goede python omgeving om in te werken.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dac5f3",
   "metadata": {},
   "source": [
    "2. Installeer spacy in de anaconda terminal\n",
    "<div class=\"alert alert-block alert-info\">conda install -c conda-forge spacy </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650f1c1",
   "metadata": {},
   "source": [
    "### Installeer spacy for linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a862f4",
   "metadata": {},
   "source": [
    "In een terminal met python geinstalleerd\n",
    "<div class=\"alert alert-block alert-info\">pip install spacy && pip install unicode</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ef020",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">Nadat u de installatie volbracht heeft kan u kiezen of u het europese of het amerikaanse model wilt gebruiken. De commandos blijven hetzelfde, deze moeten enkel in de juiste map uitgevoerd worden, EU of USA.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c9769",
   "metadata": {},
   "source": [
    "## [Extracting_data_pickle_naar_csv](#Extracting_data_pickle_naar_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e073749",
   "metadata": {},
   "source": [
    "Dit script doet hetvolgende:\n",
    "1. Dit script start met het kiezen van een pickle file.\n",
    "2. Colommen **address_1, address_2, person_ctry_code** apart nemen\n",
    "3. Drop all NAN records\n",
    "4. Sorteren op **person_ctry_code** en enkel EU landen\n",
    "5. **address_1 en address_2** in een csv file extracten\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">Het gedeelte in commentaar doet het zelfde maar dan met de colommen <b>street, city, zip_code.</b> Hiervoor hebben we ondervonden dat er minder ingevulde records zijn.</div>\n",
    "Windows\n",
    "<div class=\"alert alert-block alert-info\">python create-labled-data_EU.py</div>\n",
    "Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 create-labled-data_EU.py</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cb0ba",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0fe296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on street:  5497\n",
      "failed on city:  3139\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "f = open(\"./EU/output/fouten_generate.txt\", 'w')\n",
    "f.close\n",
    "df = pd.read_pickle(\"./EU/data/samples/500ksample.pkl\")\n",
    "\n",
    "# extract_street = df.filter(items=['street', 'city', 'zip_code', 'person_ctry_code'])\n",
    "# dropstreet = extract_street.dropna()\n",
    "# filterstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# nostreet = filterstreet[filterstreet['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]\n",
    "# dropstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# newstreet = dropstreet[dropstreet['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]]\n",
    "# pf = pf.groupby(['person_ctry_code'])\n",
    "\n",
    "df = df.filter(items=['address_1', 'address_2', 'person_ctry_code'])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(by=[('person_ctry_code')])\n",
    "df = df[df['person_ctry_code'].isin(['AT','BE','BG','CY','CZ','DE','DK','EE','ES','FI','FR','GR','HR','HU','IE','IT','LT','LU','LV','MT','NL','PO','PT','RO','SE','SI','SK'])]\n",
    "df = df.filter(items=['address_1', 'address_2', 'person_ctry_code'])\n",
    "df = df.drop_duplicates()\n",
    "def transliterate(row):\n",
    "    row[0] = unidecode(row[0])\n",
    "    row[1] = unidecode(row[1])\n",
    "    row[2] = unidecode(row[2])\n",
    "\n",
    "df.apply(lambda x: transliterate(x),axis=1)\n",
    "df.to_pickle('./EU/data/samples/500ksample-europefilter-address.pkl')\n",
    "\n",
    "stringf = pd.DataFrame(columns=['full_address', 'straat', 'nummer', 'city', 'zipcode'])\n",
    "spanf = pd.DataFrame(columns=['full_address', 'straat', 'nummer', 'city', 'zipcode'])\n",
    "\n",
    "fail_numberstreet = 0\n",
    "fail_cityzip = 0\n",
    "\n",
    "def get_address(row):\n",
    "    global fail_numberstreet\n",
    "    global fail_cityzip\n",
    "    full_address = row['address_1'] + ',' + row['address_2']\n",
    "    totale_lengte_straat = len(row['address_1']) + 1\n",
    "    straat = \"\"\n",
    "    nummer = \"\"\n",
    "    city = \"\"\n",
    "    zipcode = \"\"\n",
    "    straatspan = \"\"\n",
    "    nummerspan = \"\"\n",
    "    cityspan = \"\"\n",
    "    zipcodespan = \"\"\n",
    "    if re.match('^([0-9\\-]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+)', row[0]):\n",
    "        split = re.search('^([0-9\\-]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+)', row[0])\n",
    "        straat = split.group(3)\n",
    "        nummer = split.group(1)\n",
    "        straatspan = split.span(3)\n",
    "        nummerspan = split.span(1)\n",
    "    # straat + nummer\n",
    "    elif re.match('^([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+) ([0-9\\/\\-]+( ?[a-zA-Z]*)?)', row[0]):\n",
    "        split = re.search('^([ \\u00C0-\\u017Fa-zA-Z\\'\\-]+) ([0-9\\/\\-]+( ?[a-zA-Z]*)?)', row[0])\n",
    "        straat = split.group(1)\n",
    "        nummer = split.group(2)\n",
    "        straatspan = split.span(1)\n",
    "        nummerspan = split.span(2)\n",
    "    else:\n",
    "        f = open(\"./EU/output/fouten_generate.txt\", 'a')\n",
    "        f.write(\"street/nummer: \" + full_address + \"\\n\")\n",
    "        f.close()\n",
    "        fail_numberstreet += 1\n",
    "    \n",
    "    # zipcode + city\n",
    "    if re.match('([ A-Z-]*[0-9]+( ?[A-Z]{2})?) ?([\\u00C0-\\u0338a-zA-Z ./-]+)$', row[1]):\n",
    "        split = re.search('([ A-Z-]*[0-9]+( ?[A-Z]{2})?) ?([\\u00C0-\\u0338a-zA-Z ./-]+)$', row[1])\n",
    "        zipcode = split.group(1)\n",
    "        city = split.group(3)\n",
    "        zipcodespan = list(split.span(1))\n",
    "        cityspan = list(split.span(3))\n",
    "        zipcodespan[0] += totale_lengte_straat\n",
    "        zipcodespan[1] += totale_lengte_straat\n",
    "        cityspan[0] += totale_lengte_straat\n",
    "        cityspan[1] += totale_lengte_straat\n",
    "\n",
    "    # city + zipcode \n",
    "    elif re.match('([\\u00C0-\\u017Fa-zA-Z ./-]+) ?([ A-Z-]*[0-9]+)$', row[1]):\n",
    "        split = re.search('([\\u00C0-\\u017Fa-zA-Z ./-]+) ?([ A-Z-]*[0-9]+)$', row[1])\n",
    "        zipcode = split.group(2)\n",
    "        city = split.group(1)\n",
    "        zipcodespan = list(split.span(2))\n",
    "        cityspan = list(split.span(1))\n",
    "        zipcodespan[0] += totale_lengte_straat\n",
    "        zipcodespan[1] += totale_lengte_straat\n",
    "        cityspan[0] += totale_lengte_straat\n",
    "        cityspan[1] += totale_lengte_straat\n",
    "    else:\n",
    "        f = open(\"./EU/output/fouten_generate.txt\", 'a')\n",
    "        f.write(\"city: \" + full_address + \"\\n\")\n",
    "        f.close()\n",
    "        fail_cityzip += 1\n",
    "    valuesstring = np.array([full_address, straat, nummer, city, zipcode], dtype=object)\n",
    "    valuesspan = np.array([full_address, straatspan, nummerspan, cityspan, zipcodespan], dtype=object)\n",
    "    stringf.loc[row.name,:]=valuesstring\n",
    "    spanf.loc[row.name,:]=valuesspan\n",
    "    \n",
    "\n",
    "df.apply(lambda x: get_address(x),axis=1)\n",
    "\n",
    "stringf.to_pickle(\"./EU/data/lableddata/stringformat.pkl\")\n",
    "spanf.to_pickle(\"./EU/data/lableddata/spanformat.pkl\")\n",
    "\n",
    "print(\"failed on street: \", fail_numberstreet)\n",
    "print(\"failed on city: \", fail_cityzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513261e",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2522a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on number:  1793\n",
      "failed on street:  1373\n",
      "failed on city:  3304\n",
      "failed on zipcode:  1037\n",
      "failed on state:  1533\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "df = pd.read_pickle(\"./USA/data/samples/500ksample.pkl\")\n",
    "\n",
    "#STREET CITY ZIPCODE\n",
    "# extract_street = df.filter(items=['street', 'city', 'zip_code', 'person_ctry_code'])\n",
    "# dropstreet = extract_street.dropna()\n",
    "# filterstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# nostreet = filterstreet[filterstreet['person_ctry_code'].isin(['US'])]\n",
    "# dropstreet = dropstreet.sort_values(by=[('person_ctry_code')])\n",
    "# newstreet = dropstreet[dropstreet['person_ctry_code'].isin(['US'])]]\n",
    "# pf = pf.groupby(['person_ctry_code'])\n",
    "\n",
    "#ADDRESS1 ADDRESS2\n",
    "df = df.filter(items=['address_1', 'address_2', 'person_ctry_code'])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(by=[('person_ctry_code')])\n",
    "df = df[df['person_ctry_code'].isin(['US'])]\n",
    "df = df.filter(items=['address_1', 'address_2'])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.to_pickle('./USA/data/samples/500ksample-americanfilter-address.pkl')\n",
    "\n",
    "stringf = pd.DataFrame(columns=['full_address', 'straat', 'nummer', 'city', 'zipcode', 'state'])\n",
    "spanf = pd.DataFrame(columns=['full_address', 'straat', 'nummer', 'city', 'zipcode', 'state'])\n",
    "\n",
    "fail_nummer = 0\n",
    "fail_straat = 0\n",
    "fail_city = 0\n",
    "fail_zipcode = 0\n",
    "fail_state = 0\n",
    "\n",
    "def fout(element,adres, fails):\n",
    "    f = open(\"./USA/output/fouten_generate.txt\", 'a')\n",
    "    f.write(element + \": \" + adres + \"\\n\")\n",
    "    f.close()\n",
    "    return fails + 1\n",
    "\n",
    "def get_address(row):\n",
    "    global fail_nummer\n",
    "    global fail_straat\n",
    "    global fail_city\n",
    "    global fail_zipcode\n",
    "    global fail_state\n",
    "    nummer = \"\"\n",
    "    nummerspan = \"\"\n",
    "    straat = \"\"\n",
    "    straatspan = \"\"\n",
    "    city = \"\"\n",
    "    cityspan = \"\"\n",
    "    zipcode = \"\"\n",
    "    zipcodespan = \"\"\n",
    "    state = \"\"\n",
    "    statespan = \"\"\n",
    "    row[0] = unidecode(row[0])\n",
    "    row[1] = unidecode(row[1])\n",
    "    full_address = row.address_1 + ',' + row.address_2\n",
    "    totale_lengte_straat = len(row[0]) + 1\n",
    "    if re.match('(/ )?([0-9]+)', row[0]):\n",
    "        nummer = re.search('(/ )?([0-9]+)', row[0]).group(2)\n",
    "        nummerspan = re.search('(/ )?([0-9]+)', row[0]).span(2)\n",
    "    else:\n",
    "        fail_nummer = fout(\"Nummer\", row[0], fail_nummer)\n",
    "    #straat\n",
    "    if re.search('[0-9]+ ([\\s\\S]*)$', row[0]):\n",
    "        straat = re.search('[0-9]+ ([\\s\\S]*)$', row[0]).group(1)\n",
    "        straatspan = re.search('[0-9]+ ([\\s\\S]*)$', row[0]).span(1)\n",
    "    else:\n",
    "        fail_straat = fout(\"Straat\", row[0], fail_straat)\n",
    "        \n",
    "    #city\n",
    "    if re.match('([a-zA-Z ]+?(?=,))', row[1]):\n",
    "        city = re.search('([a-zA-Z ]+?(?=,))', row[1]).group(1)\n",
    "        cityspan = re.search('([a-zA-Z ]+?(?=,))', row[1]).span(1)\n",
    "        cityspan = list(cityspan)\n",
    "        cityspan[0] += totale_lengte_straat\n",
    "        cityspan[1] += totale_lengte_straat\n",
    "    else:\n",
    "        fail_city = fout(\"City\", row[1], fail_city)\n",
    "    #zipcode\n",
    "    if re.search('([0-9\\-]+$)', row[1]):\n",
    "        zipcode = re.search('([0-9\\-]+$)', row[1]).group(1)\n",
    "        zipcodespan = re.search('([0-9\\-]+$)', row[1]).span(1)\n",
    "        zipcodespan = list(zipcodespan)\n",
    "        zipcodespan[0] += totale_lengte_straat\n",
    "        zipcodespan[1] += totale_lengte_straat\n",
    "    else:\n",
    "        fail_zipcode = fout(\"Zipcode\", row[1], fail_zipcode)\n",
    "    #state\n",
    "    if re.search('(,? )([ A-Za-z]*)(?<! ),? [0-9]', row[1]):\n",
    "        state = re.search('(,? )([ A-Za-z]*)(?<! ),? [0-9]', row[1]).group(2)\n",
    "        statespan = re.search('(,? )([ A-Za-z]*)(?<! ),? [0-9]', row[1]).span(2)\n",
    "        statespan = list(statespan)\n",
    "        statespan[0] += totale_lengte_straat\n",
    "        statespan[1] += totale_lengte_straat\n",
    "                \n",
    "    else:\n",
    "        fail_state = fout(\"State\", row[1], fail_state)\n",
    "\n",
    "    valuesstring = np.array([full_address, straat, nummer, city, zipcode, state], dtype=object)\n",
    "    valuesspan = np.array([full_address, straatspan, nummerspan, cityspan, zipcodespan, statespan], dtype=object)\n",
    "    stringf.loc[row.name,:]=valuesstring\n",
    "    spanf.loc[row.name,:]=valuesspan\n",
    "\n",
    "df.apply(lambda x: get_address(x),axis=1)\n",
    "\n",
    "stringf.to_pickle(\"./USA/data/lableddata/stringformat.pkl\")\n",
    "spanf.to_pickle(\"./USA/data/lableddata/spanformat.pkl\")\n",
    "\n",
    "print(\"failed on number: \", fail_nummer)\n",
    "print(\"failed on street: \", fail_straat)\n",
    "print(\"failed on city: \", fail_city)\n",
    "print(\"failed on zipcode: \", fail_zipcode)\n",
    "print(\"failed on state: \", fail_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a03a2e",
   "metadata": {},
   "source": [
    "## [Genereer_trainingdata](#Genereer_trainingdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383883c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parsing a csv file with USAropean addresses to spaCy readable format\n",
    "Dit script gaat ons trainings data bezorgen van een op voorhand gegenereerde csv file.\n",
    "Doormiddel van gebruik van regex\n",
    "<!-- > TODO: regex uitleggen -->\n",
    "Om onze trainingsdata te genereren moeten we eerst en vooral zorgen dat onze data uit de pickel file wordt ingelezen en geparset naar het correcte formaat. In ons script ```parser.py``` checken we elke entry op verschillende patronen om te bepalen of ze bruikbaar zijn.\n",
    "Eerst en vooral checken we met \n",
    "> ```(.*),(.*)``` \n",
    "\n",
    "of de string een komma bevat met ervoor en erna telkens een groep van karakters. Als de string voldoet aan deze voorwaarde splitsen we de string op in 2 groepen, groep 1 zijnde het straat-gedeelte van het adres en groep 2 zijnde het gemeente gedeelte van het adres. Vervolgens gaan we een aantal meer specifieke reguliere expressies toepassen om te verifieren of de string hier aan voldoet. \n",
    "Die eerste reguliere expressie die we gebruiken is \n",
    "> ```(^(.*) ([0-9]{3,5}-[0-9]{4}))```\n",
    "\n",
    "We passen deze toe op het gemeente-gedeelte van de originele string.\n",
    "Deze regex doet het volgende:\n",
    "* Is er een opeenvolging van eender welke karakters (groep 1)\n",
    "* volgt na deze groep 1 een spatie\n",
    "* volgt na de spatie een nieuwe groep (groep 2) bestaande uit: 3, 4 of 5 cijfers \n",
    "gevolgd door een '-' gevolgd door opnieuw 4 cijfers.\n",
    "Als deze groepen aanwezig zijn hebben we dus een string met de stad (groep 1) en een string met de postcode (groep 2).\n",
    "\n",
    "Als volgende hebben we een reguliere expressie die specifiek voor Nederland geldt:\n",
    "> ```(^([0-9]{4} [A-Z]{2}) (.*))```\n",
    "\n",
    "Deze regex matcht 2 groepen:\n",
    "groep 1:\n",
    "* 4 opeenvolgende cijfers\n",
    "* een spatie\n",
    "* 2 opeenvolgende hoofdletters\n",
    "groep 2:\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "\n",
    "Als laatste hebben we 2 reguliere expressies specifiek voor de VS, Belgie en Duitsland in 2 formaten.\n",
    "Formaat 1:\n",
    "> ```((^[0-9]{4,5}) (.*))```\n",
    "\n",
    "* 4 of 5 opeenvolgende cijfers\n",
    "* een spatie\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "Formaat 2:\n",
    "> ```(^(.*) [0-9]{4,5})```\n",
    "\n",
    "* een ongelimiteerde opeenvolging van karakters\n",
    "* een spatie\n",
    "* 4 of 5 opeenvolgende cijfers\n",
    "\n",
    "<div>\n",
    "Dit script maakt een \"training_EU.py\" file in de map /data/trainingData\n",
    "</div>\n",
    "<div>\n",
    "De data komt in het formaar:\n",
    "</div>\n",
    "\n",
    "<blockquote>\n",
    "TRAININGS_DATA = [<br>\n",
    "    &emsp;(\"Heipelweg 7,A-8700 Leoben\",[(0,9, \"STREET\"),(10,11, \"NUMBER\"),(19,25, \"CITY\"),(12,18, \"ZIPCODE\")]),<br>\n",
    "    &emsp;...<br>\n",
    "    ]<br>\n",
    "</blockquote>\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python generate-spacy-format.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 generate-spacy-format.py</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee93a2",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1a9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_pickle(\"./EU/data/lableddata/spanformat.pkl\")\n",
    "\n",
    "counter = 0\n",
    "train = \"\"\n",
    "dev = \"\"\n",
    "validation = \"\"\n",
    "\n",
    "def formatline(row):\n",
    "    global counter\n",
    "    global train\n",
    "    global dev\n",
    "    global validation\n",
    "    if not (row.straat == \"\" and row.nummer == \"\" and row.city == \"\" and row.zipcode == \"\"):\n",
    "        line = \"\\t(\\\"\"+row.full_address+\"\\\",\"+\"[\"\n",
    "        valit = row.full_address\n",
    "        if row.straat != \"\":\n",
    "            line += \"(\"+str(row.straat[0])+\",\"+str(row.straat[1])+\", \\\"STREET\\\"),\"\n",
    "            valit += \"&\"+str(row.straat[0]) + \";\" + str(row.straat[1]) + \";STREET\"\n",
    "        if row.nummer != \"\":\n",
    "            line += \"(\"+str(row.nummer[0])+\",\"+str(row.nummer[1])+\", \\\"NUMBER\\\"),\"\n",
    "            valit += \"&\"+str(row.nummer[0]) + \";\" + str(row.nummer[1]) + \";NUMBER\"\n",
    "        if row.city != \"\":\n",
    "            line += \"(\"+str(row.city[0])+\",\"+str(row.city[1])+\", \\\"CITY\\\"),\"\n",
    "            valit += \"&\"+str(row.city[0])+\";\"+str(row.city[1])+\";CITY\"\n",
    "        if row.zipcode != \"\":\n",
    "            line += \"(\"+str(row.zipcode[0])+\",\"+str(row.zipcode[1])+\", \\\"ZIPCODE\\\"),\"\n",
    "            valit += \"&\"+str(row.zipcode[0])+\";\"+str(row.zipcode[1])+\";ZIPCODE\"\n",
    "        line += \"]),\\n\"\n",
    "        valit += \"\\n\"\n",
    "\n",
    "        validation += valit\n",
    "        counter += 1\n",
    "        if counter < 5:\n",
    "            train += line\n",
    "        else:\n",
    "            dev += line\n",
    "            counter = 0\n",
    "\n",
    "df.apply(lambda x: formatline(x),axis=1)\n",
    "\n",
    "f = open(\"./EU/output/fouten_generate.txt\", 'w')\n",
    "f.close\n",
    "f = open(\"./EU/data/validation/validation_EU.txt\", 'w')\n",
    "f.close\n",
    "f = open(\"./EU/data/trainingData/training_EU.py\", 'w')\n",
    "f.write(\"TRAININGS_DATA = [\\n\" + train + \"]\")\n",
    "f.close()\n",
    "f = open(\"./EU/data/trainingData/dev_EU.py\", 'w')\n",
    "f.write(\"TRAININGS_DATA = [\\n\" + dev + \"]\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"./EU/data/validation/validation_EU.txt\", 'w')\n",
    "f.write(validation)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cef1f5",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3b2aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_pickle(\"./USA/data/lableddata/spanformat.pkl\")\n",
    "\n",
    "counter = 0\n",
    "train = \"\"\n",
    "dev = \"\"\n",
    "validation = \"\"\n",
    "\n",
    "def formatline(row):\n",
    "    global counter\n",
    "    global train\n",
    "    global dev\n",
    "    global validation\n",
    "    if not (row.straat == \"\" and row.nummer == \"\" and row.city == \"\" and row.zipcode == \"\" and row.state == \"\"):\n",
    "        line = \"\\t(\\\"\"+row.full_address+\"\\\",\"+\"[\"\n",
    "        valit = row.full_address\n",
    "        if row.straat != \"\":\n",
    "            line += \"(\"+str(row.straat[0])+\",\"+str(row.straat[1])+\", \\\"STREET\\\"),\"\n",
    "            valit += \"&\"+str(row.straat[0]) + \";\" + str(row.straat[1]) + \";STREET\"\n",
    "        if row.nummer != \"\":\n",
    "            line += \"(\"+str(row.nummer[0])+\",\"+str(row.nummer[1])+\", \\\"NUMBER\\\"),\"\n",
    "            valit += \"&\"+str(row.nummer[0]) + \";\" + str(row.nummer[1]) + \";NUMBER\"\n",
    "        if row.city != \"\":\n",
    "            line += \"(\"+str(row.city[0])+\",\"+str(row.city[1])+\", \\\"CITY\\\"),\"\n",
    "            valit += \"&\"+str(row.city[0])+\";\"+str(row.city[1])+\";CITY\"\n",
    "        if row.zipcode != \"\":\n",
    "            line += \"(\"+str(row.zipcode[0])+\",\"+str(row.zipcode[1])+\", \\\"ZIPCODE\\\"),\"\n",
    "            valit += \"&\"+str(row.zipcode[0])+\";\"+str(row.zipcode[1])+\";ZIPCODE\"\n",
    "        if row.state != \"\":\n",
    "            if row.city == \"\" or not row.city[1] >= row.state[0]:\n",
    "                line += \"(\"+ str(row.state[0])+\",\"+str(row.state[1])+\", \\\"STATE\\\")\"\n",
    "                valit += \"&\"+str(row.state[0])+\";\"+str(row.state[1])+\";STATE\"\n",
    "        line += \"]),\\n\"\n",
    "        valit += \"\\n\"\n",
    "\n",
    "        validation += valit\n",
    "        counter += 1\n",
    "        if counter < 5:\n",
    "            train += line\n",
    "        else:\n",
    "            dev += line\n",
    "            counter = 0\n",
    "\n",
    "df.apply(lambda x: formatline(x),axis=1)\n",
    "\n",
    "f = open(\"./USA/output/fouten_generate.txt\", 'w')\n",
    "f.close\n",
    "f = open(\"./USA/data/validation/validation_USA.txt\", 'w')\n",
    "f.close\n",
    "f = open(\"./USA/data/trainingData/training_USA.py\", 'w')\n",
    "f.write(\"TRAININGS_DATA = [\\n\" + train + \"]\")\n",
    "f.close()\n",
    "f = open(\"./USA/data/trainingData/dev_USA.py\", 'w')\n",
    "f.write(\"TRAININGS_DATA = [\\n\" + dev + \"]\")\n",
    "f.close()\n",
    "\n",
    "f = open(\"./USA/data/validation/validation_USA.txt\", 'w')\n",
    "f.write(validation)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60493d9",
   "metadata": {},
   "source": [
    "## [Prepare_binarydata](#Prepare_binarydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d66c1",
   "metadata": {},
   "source": [
    "In geval van Europa wordt de \"/EU/data/trainingData/training_EU.py\" file omgezet naar binaire data. <br>\n",
    "Dit wordt dan in de map \"/EU/data/binaryData/\" als spacy file aangemaakt. De \"train.spacy\" is de data dat gebruikt wordt als training. Dit is 80% van de totale gegenereerde trainingsdata <br>\n",
    "\"dev.spacy\" is de validatiedata dat gebruikt wordt bij het trainen van het model. Dit is de resterende 20% van de totale trainingsdata.\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python PrepareData.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 PrepareData.py</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da609486",
   "metadata": {},
   "source": [
    "### PrepareData.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629668f",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390a1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "from spacy.tokens import DocBin\n",
    "sys.path.insert(0, './EU/data/trainingData')\n",
    "from training_EU import TRAININGS_DATA as TD\n",
    "from dev_EU import TRAININGS_DATA as DD\n",
    "\n",
    "f = open(\"./EU/output/problems.txt\", 'w')\n",
    "f.close()\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            f = open(\"./EU/output/problems.txt\", 'a')\n",
    "            f.write(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\\n\")\n",
    "            f.close()\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./EU/data/binaryData/train.spacy\")\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in DD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./EU/data/binaryData/dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce80039",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75c096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "from spacy.tokens import DocBin\n",
    "sys.path.insert(0, './USA/data/trainingData')\n",
    "from training_USA import TRAININGS_DATA as TD\n",
    "from dev_USA import TRAININGS_DATA as DD\n",
    "\n",
    "f = open(\"./USA/output/fouten_dataprepare.txt\", 'w')\n",
    "f.close()\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            f = open(\"./USA/output/fouten_dataprepare.txt\", 'a')\n",
    "            f.write(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\\n\")\n",
    "            f.close()\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./USA/data/binaryData/train.spacy\")\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in DD:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./USA/data/binaryData/dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e862d",
   "metadata": {},
   "source": [
    "## [Start_training](#Start_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0281e3",
   "metadata": {},
   "source": [
    "Hier komt het moment waar we kunnen beginnen met trainen van het model. Dit gebeurt via de command line. <br>\n",
    "De spacy train geeft aan dat we de training starten. Vervolgens wordt de config file meegegeven. Bij het \"--output\" argument staat de locatie waar we het model opslaan. In deze map komt het best gevonden model en het laatste aangemaakte model.<br>\n",
    "\n",
    "Tokenization is een proces waarbij er tekst word onderverdeeld in verschillende segmenten, deze segmenten worden tokens genoemd. Dus eerst ‘tokenizeert’ spaCy jouw tekst in meerdere segmenten. Deze segmenten worden bepaald op basis van woorden, punctuatie (bijvoorbeeld aan het einde van een zin). Zo moet je uitkijken want U.K. bijvoorbeeld moet gezien worden als 1 token.\n",
    "\n",
    "We maakten gebruik van tokenizers omdat de komma’s in onze dataset een probleem waren. Blijkbaar werden komma’s gezien door SpaCy als een ingebouwde symbool, dus getallen tussen een komma werden gezien als een double, terwijl dit integers moesten voorstellen.\n",
    "Eerst wouden we alle komma’s vervangen door een punt komma of door een spatie, maar dit gaf nog steeds problemen. Met behulp van tokenization konden we de komma zien als een eigen ‘token’ en werden de integers niet meer beschouwd als een double.\n",
    "> Het adres  \"Wagramer Strasse 17,1220 Vienna\" was dus een probleem, aangezien het straatnummer 17 en postcode 1220 niet werden gezien als twee integers, maar als een double. \n",
    "\n",
    "> dit laat zien hoe een tokenizer een adres opdeelt in segmenten:\n",
    "\"Am Kirchwald 347,6100 Seefeld\" => \"Am\"; \"Kirchwald\"; \"347\"; \",\"; \"6100\"; \"Seefeld\"\n",
    "\n",
    "https://spacy.io/api/tokenizer\n",
    "\n",
    "https://spacy.io/usage/linguistic-features#how-tokenizer-works\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python TrainModel.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 TrainModel.py</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecaf75f",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7d791",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59febd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-10 15:58:02,955] [INFO] Set up nlp object from config\n",
      "[2022-03-10 15:58:02,965] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-03-10 15:58:03,101] [INFO] Created vocabulary\n",
      "[2022-03-10 15:58:03,101] [INFO] Finished initializing nlp object\n",
      "[2022-03-10 15:58:12,261] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: EU/model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     72.72    7.31    5.22   12.19    0.07\n",
      "  0     200        215.40   3866.50   95.45   93.29   97.72    0.95\n",
      "  0     400        224.65   1274.57   97.37   97.09   97.65    0.97\n",
      "  1     600        193.37    904.20   98.20   98.25   98.16    0.98\n",
      "  1     800        251.05    720.16   98.45   98.36   98.54    0.98\n",
      "  2    1000        254.23    715.91   98.80   98.78   98.82    0.99\n",
      "  2    1200        331.94    524.72   98.67   98.25   99.09    0.99\n",
      "  3    1400        342.59    425.18   98.91   98.74   99.07    0.99\n",
      "  4    1600        420.09    439.51   98.92   98.93   98.91    0.99\n",
      "  6    1800        459.19    322.78   98.95   98.91   98.98    0.99\n",
      "  8    2000        502.10    285.79   98.98   99.07   98.89    0.99\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "EU/model/model-last\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python3 -m spacy train config_EU.cfg --output ./EU/model --code ./EU/config/CustomTokenizer.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4283f",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c743218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-10 16:01:38,182] [INFO] Set up nlp object from config\n",
      "[2022-03-10 16:01:38,192] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-03-10 16:01:38,338] [INFO] Created vocabulary\n",
      "[2022-03-10 16:01:38,338] [INFO] Finished initializing nlp object\n",
      "[2022-03-10 16:01:45,974] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: USA/model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     67.68   12.85    9.47   19.98    0.13\n",
      "  0     200        171.42   3667.73   96.89   96.23   97.56    0.97\n",
      "  0     400        155.27    934.43   97.14   96.25   98.05    0.97\n",
      "  0     600        165.67    889.64   97.85   97.35   98.36    0.98\n",
      "  1     800        177.33    800.26   98.31   97.93   98.70    0.98\n",
      "  1    1000        213.12    837.57   98.27   98.33   98.22    0.98\n",
      "  2    1200        230.39    756.11   98.60   98.38   98.82    0.99\n",
      "  3    1400        331.95    809.15   98.39   97.91   98.87    0.98\n",
      "  4    1600        345.67    676.04   98.48   98.17   98.79    0.98\n",
      "  5    1800        354.68    607.07   98.49   98.19   98.78    0.98\n",
      "  7    2000        416.22    508.63   98.46   98.24   98.68    0.98\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "USA/model/model-last\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"python3 -m spacy train config_USA.cfg --output ./USA/model --code ./USA/config/CustomTokenizer.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbe897",
   "metadata": {},
   "source": [
    "## [Recall_And_Precision_plus_Visualiseer_model](#Recall_And_Precision_plus_Visualiseer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f001181",
   "metadata": {},
   "source": [
    "In volgende code kan u een visueel beeld krijgen van uitkomsten die het model heeft gevonden.<br>\n",
    "Dit kan gedaan worden door een csv file mee te geven. Of door zelf adressen in te geven in de list die momenteel in commentaar staat. <br>\n",
    "Erna wordt het model gekozen hier hebt u de keuze uit het beste model of het laatste model.\n",
    "<div>nlp = spacy.load(\"./model/model-best\") of<br>\n",
    "nlp = spacy.load(\"./model/model-last\")</div>\n",
    "\n",
    "\n",
    "#### Windows\n",
    "<div class=\"alert alert-block alert-info\">python TestModel.py</div>\n",
    "\n",
    "#### Linux\n",
    "<div class=\"alert alert-block alert-info\">python3 TestModel.py</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">We hebben de laatste 3 regels in commentaar geplaatst zodat de output van de Jupyter notebook niet te lang werd. We raden aan om het commando in terminal uit te voeren als u de volledige uitkomst wilt bekijken. U kan het resultaat bekijken door naar de link <a href=\"http://localhost:5000\">http://localhost:5000</a> te gaan.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03ca51",
   "metadata": {},
   "source": [
    "### EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1457b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "straat: 1 percentage: 100.0%\n",
      "nummer: 1 percentage: 100.0%\n",
      "city: 1 percentage: 100.0%\n",
      "zipcode: 1 percentage: 100.0%\n",
      "counter: 1\n",
      "----------------------AT--------------------------------\n",
      "straat: 334 percentage: 84.98727735368958%\n",
      "nummer: 329 percentage: 83.7150127226463%\n",
      "city: 360 percentage: 91.6030534351145%\n",
      "zipcode: 369 percentage: 93.89312977099237%\n",
      "counter: 393\n",
      "----------------------BE--------------------------------\n",
      "straat: 282 percentage: 61.97802197802198%\n",
      "nummer: 278 percentage: 61.0989010989011%\n",
      "city: 351 percentage: 77.14285714285715%\n",
      "zipcode: 381 percentage: 83.73626373626374%\n",
      "counter: 455\n",
      "----------------------BG--------------------------------\n",
      "straat: 1 percentage: 16.666666666666664%\n",
      "nummer: 1 percentage: 16.666666666666664%\n",
      "city: 3 percentage: 50.0%\n",
      "zipcode: 4 percentage: 66.66666666666666%\n",
      "counter: 6\n",
      "----------------------CY--------------------------------\n",
      "straat: 6 percentage: 75.0%\n",
      "nummer: 5 percentage: 62.5%\n",
      "city: 4 percentage: 50.0%\n",
      "zipcode: 7 percentage: 87.5%\n",
      "counter: 8\n",
      "----------------------CZ--------------------------------\n",
      "straat: 51 percentage: 82.25806451612904%\n",
      "nummer: 51 percentage: 82.25806451612904%\n",
      "city: 22 percentage: 35.483870967741936%\n",
      "zipcode: 27 percentage: 43.54838709677419%\n",
      "counter: 62\n",
      "----------------------DE--------------------------------\n",
      "straat: 4672 percentage: 78.6929425635843%\n",
      "nummer: 4656 percentage: 78.4234461849419%\n",
      "city: 5151 percentage: 86.76099039919151%\n",
      "zipcode: 5281 percentage: 88.95064847566111%\n",
      "counter: 5937\n",
      "----------------------DK--------------------------------\n",
      "straat: 329 percentage: 82.04488778054862%\n",
      "nummer: 316 percentage: 78.80299251870323%\n",
      "city: 341 percentage: 85.03740648379052%\n",
      "zipcode: 361 percentage: 90.02493765586036%\n",
      "counter: 401\n",
      "----------------------EE--------------------------------\n",
      "straat: 7 percentage: 63.63636363636363%\n",
      "nummer: 6 percentage: 54.54545454545454%\n",
      "city: 6 percentage: 54.54545454545454%\n",
      "zipcode: 8 percentage: 72.72727272727273%\n",
      "counter: 11\n",
      "----------------------ES--------------------------------\n",
      "straat: 96 percentage: 15.09433962264151%\n",
      "nummer: 75 percentage: 11.79245283018868%\n",
      "city: 305 percentage: 47.9559748427673%\n",
      "zipcode: 337 percentage: 52.987421383647806%\n",
      "counter: 636\n",
      "----------------------FI--------------------------------\n",
      "straat: 301 percentage: 79.41952506596306%\n",
      "nummer: 291 percentage: 76.78100263852242%\n",
      "city: 297 percentage: 78.3641160949868%\n",
      "zipcode: 337 percentage: 88.91820580474933%\n",
      "counter: 379\n",
      "----------------------FR--------------------------------\n",
      "straat: 1233 percentage: 41.82496607869742%\n",
      "nummer: 1270 percentage: 43.08005427408412%\n",
      "city: 2259 percentage: 76.62822252374491%\n",
      "zipcode: 2287 percentage: 77.57801899592944%\n",
      "counter: 2948\n",
      "----------------------GR--------------------------------\n",
      "straat: 22 percentage: 57.89473684210527%\n",
      "nummer: 24 percentage: 63.1578947368421%\n",
      "city: 13 percentage: 34.21052631578947%\n",
      "zipcode: 15 percentage: 39.473684210526315%\n",
      "counter: 38\n",
      "----------------------HR--------------------------------\n",
      "straat: 5 percentage: 100.0%\n",
      "nummer: 5 percentage: 100.0%\n",
      "city: 5 percentage: 100.0%\n",
      "zipcode: 5 percentage: 100.0%\n",
      "counter: 5\n",
      "----------------------HU--------------------------------\n",
      "straat: 25 percentage: 25.773195876288657%\n",
      "nummer: 24 percentage: 24.742268041237114%\n",
      "city: 85 percentage: 87.62886597938144%\n",
      "zipcode: 87 percentage: 89.69072164948454%\n",
      "counter: 97\n",
      "----------------------IE--------------------------------\n",
      "straat: 76 percentage: 46.62576687116564%\n",
      "nummer: 79 percentage: 48.466257668711656%\n",
      "city: 5 percentage: 3.067484662576687%\n",
      "zipcode: 18 percentage: 11.042944785276074%\n",
      "counter: 163\n",
      "----------------------IT--------------------------------\n",
      "straat: 457 percentage: 32.31966053748232%\n",
      "nummer: 450 percentage: 31.824611032531823%\n",
      "city: 637 percentage: 45.04950495049505%\n",
      "zipcode: 714 percentage: 50.495049504950494%\n",
      "counter: 1414\n",
      "----------------------LT--------------------------------\n",
      "straat: 1 percentage: 25.0%\n",
      "nummer: 1 percentage: 25.0%\n",
      "city: 4 percentage: 100.0%\n",
      "zipcode: 4 percentage: 100.0%\n",
      "counter: 4\n",
      "----------------------LU--------------------------------\n",
      "straat: 13 percentage: 41.935483870967744%\n",
      "nummer: 13 percentage: 41.935483870967744%\n",
      "city: 25 percentage: 80.64516129032258%\n",
      "zipcode: 25 percentage: 80.64516129032258%\n",
      "counter: 31\n",
      "----------------------LV--------------------------------\n",
      "straat: 5 percentage: 62.5%\n",
      "nummer: 4 percentage: 50.0%\n",
      "city: 6 percentage: 75.0%\n",
      "zipcode: 7 percentage: 87.5%\n",
      "counter: 8\n",
      "----------------------MT--------------------------------\n",
      "straat: 1 percentage: 33.33333333333333%\n",
      "nummer: 1 percentage: 33.33333333333333%\n",
      "city: 1 percentage: 33.33333333333333%\n",
      "zipcode: 1 percentage: 33.33333333333333%\n",
      "counter: 3\n",
      "----------------------NL--------------------------------\n",
      "straat: 626 percentage: 67.23952738990333%\n",
      "nummer: 625 percentage: 67.13211600429646%\n",
      "city: 624 percentage: 67.02470461868958%\n",
      "zipcode: 823 percentage: 88.39957035445757%\n",
      "counter: 931\n",
      "----------------------PT--------------------------------\n",
      "straat: 9 percentage: 14.754098360655737%\n",
      "nummer: 8 percentage: 13.114754098360656%\n",
      "city: 6 percentage: 9.836065573770492%\n",
      "zipcode: 8 percentage: 13.114754098360656%\n",
      "counter: 61\n",
      "----------------------RO--------------------------------\n",
      "straat: 1 percentage: 7.142857142857142%\n",
      "nummer: 1 percentage: 7.142857142857142%\n",
      "city: 5 percentage: 35.714285714285715%\n",
      "zipcode: 7 percentage: 50.0%\n",
      "counter: 14\n",
      "----------------------SE--------------------------------\n",
      "straat: 563 percentage: 79.9715909090909%\n",
      "nummer: 559 percentage: 79.4034090909091%\n",
      "city: 63 percentage: 8.948863636363637%\n",
      "zipcode: 98 percentage: 13.920454545454545%\n",
      "counter: 704\n",
      "----------------------SI--------------------------------\n",
      "straat: 19 percentage: 82.6086956521739%\n",
      "nummer: 19 percentage: 82.6086956521739%\n",
      "city: 20 percentage: 86.95652173913044%\n",
      "zipcode: 21 percentage: 91.30434782608695%\n",
      "counter: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3093713     None\n",
       "65461480    None\n",
       "2823340     None\n",
       "2752471     None\n",
       "2902070     None\n",
       "            ... \n",
       "94830116    None\n",
       "53277909    None\n",
       "68293677    None\n",
       "52990671    None\n",
       "91574838    None\n",
       "Length: 14747, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from curses.ascii import ctrl\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "test_text = []\n",
    "df = pd.read_pickle(\"./EU/data/samples/500ksample-europefilter-address.pkl\")\n",
    "\n",
    "labeledData = open('./EU/data/validation/validation_EU.txt', 'r')\n",
    "adreslist = []\n",
    "for line in labeledData.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    line = line.split(\"&\")\n",
    "    record = []\n",
    "    recordtuple = (line[0],record)\n",
    "    for i in line:\n",
    "        i = i.split(\";\")\n",
    "        record.append(i)\n",
    "    record.pop(0)\n",
    "    adreslist.append(recordtuple)\n",
    "\n",
    "nlp = spacy.load(\"./EU/model/model-best\")\n",
    "# nlp = spacy.load(\"./EU/model/model-last\")\n",
    "lijst = []\n",
    "correct_counter = 0\n",
    "total_counter = 0\n",
    "total_counter_straat = 0\n",
    "total_counter_nummer = 0\n",
    "total_counter_city = 0\n",
    "total_counter_zipcode = 0\n",
    "ctry_code = \"\"\n",
    "\n",
    "def validate(row):\n",
    "    global lijst\n",
    "    global correct_counter\n",
    "    global total_counter\n",
    "    global total_counter_straat\n",
    "    global total_counter_nummer\n",
    "    global total_counter_city\n",
    "    global total_counter_zipcode\n",
    "    global ctry_code\n",
    "    adres_ctry_code = row.person_ctry_code\n",
    "    full_address = row.address_1 + ',' + row.address_2\n",
    "    doc = nlp(full_address)\n",
    "    ents = list(doc.ents)\n",
    "    for at in adreslist:\n",
    "        if at[0] == str(doc):\n",
    "            for j in at[1]:\n",
    "                for token in ents:\n",
    "                    bool1 = str(j[0]) == str(token.start_char)\n",
    "                    bool2 = str(j[1]) == str(token.end_char)\n",
    "                    bool3 = j[2] == token.label_\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STREET\":\n",
    "                        total_counter_straat +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"NUMBER\":\n",
    "                        total_counter_nummer +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"CITY\":\n",
    "                        total_counter_city +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"ZIPCODE\":\n",
    "                        total_counter_zipcode +=1\n",
    "    lijst.append(doc)\n",
    "    total_counter += 1\n",
    "    if ctry_code != adres_ctry_code:\n",
    "        print(\"----------------------\" + ctry_code + \"--------------------------------\")\n",
    "        print(\"straat: \" + str(total_counter_straat) + \" percentage: \" + str(total_counter_straat / total_counter * 100)+ \"%\")\n",
    "        print(\"nummer: \" + str(total_counter_nummer) + \" percentage: \" + str(total_counter_nummer / total_counter * 100)+ \"%\")\n",
    "        print(\"city: \" + str(total_counter_city) + \" percentage: \" + str(total_counter_city / total_counter * 100)+ \"%\")\n",
    "        print(\"zipcode: \" + str(total_counter_zipcode) + \" percentage: \" + str(total_counter_zipcode / total_counter * 100)+ \"%\")\n",
    "        print(\"counter: \" + str(total_counter))\n",
    "        ctry_code = adres_ctry_code\n",
    "        total_counter = 0\n",
    "        total_counter_straat = 0\n",
    "        total_counter_nummer = 0\n",
    "        total_counter_city = 0\n",
    "        total_counter_zipcode = 0\n",
    "\n",
    "df.apply(lambda x: validate(x),axis=1)\n",
    "\n",
    "# colors = {\"STREET\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"NUMBER\": \"linear-gradient(90deg, #3f5efb, #fc466b)\", \"ZIPCODE\": \"linear-gradient(90deg, #090979, #00d4ff)\", \"CITY\": \"linear-gradient(90deg, #eeaeca, #94bbe9)\", \"OTHER\": \"linear-gradient(90deg, #22c1c3, #fdbb2d)\",}\n",
    "# options = {\"ents\": [\"CITY\", \"STREET\", \"NUMBER\", \"ZIPCODE\", \"OTHER\"], \"colors\": colors}\n",
    "# displacy.serve(lijst, style=\"ent\", options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689e304",
   "metadata": {},
   "source": [
    "### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "# test_text = [\"Keilalahdentie 4,02150 Espoo\", \"Weisshsusstrasse 2,52066 Aachen\", \"14 rue Royale,75008 Paris\", \"Hüninger Strasse 25,14195 Berlin\", \"19 bis rue Hoche,49100 Angers\"]\n",
    "test_text = []\n",
    "\n",
    "df = pd.read_pickle(\"./USA/data/samples/500ksample-americanfilter-address.pkl\")\n",
    "\n",
    "labeledData = open('./USA/data/validation/validation_USA.txt', 'r')\n",
    "adreslist = []\n",
    "for line in labeledData.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    line = line.split(\"&\")\n",
    "    record = []\n",
    "    recordtuple = (line[0],record)\n",
    "    for i in line:\n",
    "        i = i.split(\";\")\n",
    "        record.append(i)\n",
    "    record.pop(0)\n",
    "    adreslist.append(recordtuple)\n",
    "\n",
    "nlp = spacy.load(\"./USA/model/model-best\")\n",
    "# nlp = spacy.load(\"./USA/model/model-last\")\n",
    "lijst = []\n",
    "correct_counter = 0\n",
    "total_counter = 0\n",
    "total_correct_straat = 0\n",
    "total_correct_nummer = 0\n",
    "total_correct_city = 0\n",
    "total_correct_zipcode = 0\n",
    "total_correct_state = 0\n",
    "\n",
    "total_straat = 0\n",
    "total_nummer = 0\n",
    "total_city = 0\n",
    "total_zipcode = 0\n",
    "total_state = 0\n",
    "\n",
    "def validate(row):\n",
    "    global total_counter\n",
    "    global total_correct_straat\n",
    "    global total_correct_nummer\n",
    "    global total_correct_city\n",
    "    global total_correct_zipcode\n",
    "    global total_correct_state\n",
    "\n",
    "    global total_straat\n",
    "    global total_nummer\n",
    "    global total_city\n",
    "    global total_zipcode\n",
    "    global total_state \n",
    "    full_address = row.address_1 + ',' + row.address_2\n",
    "    doc = nlp(full_address)\n",
    "    ents = list(doc.ents)\n",
    "    for at in adreslist:\n",
    "        if at[0] == str(doc):\n",
    "            for j in at[1]:\n",
    "                for token in ents:\n",
    "                    bool1 = str(j[0]) == str(token.start_char)\n",
    "                    bool2 = str(j[1]) == str(token.end_char)\n",
    "                    bool3 = j[2] == token.label_\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STREET\":\n",
    "                        total_correct_straat +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"NUMBER\":\n",
    "                        total_correct_nummer +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"CITY\":\n",
    "                        total_correct_city +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"ZIPCODE\":\n",
    "                        total_correct_zipcode +=1\n",
    "                    if bool1 and bool2 and bool3 and token.label_ == \"STATE\":\n",
    "                        total_correct_state +=1\n",
    "                if j[2] == \"STREET\":\n",
    "                    total_straat += 1\n",
    "                if j[2] == \"NUMBER\":\n",
    "                    total_nummer += 1\n",
    "                if j[2] == \"CITY\":\n",
    "                    total_city += 1\n",
    "                if j[2] == \"ZIPCODE\":\n",
    "                    total_zipcode += 1\n",
    "                if j[2] == \"STATE\":\n",
    "                    total_state += 1\n",
    "    lijst.append(doc)\n",
    "    total_counter += 1\n",
    "\n",
    "df.apply(lambda x: validate(x),axis=1)\n",
    "\n",
    "print(\"straat: \" + str(total_correct_straat) + \" percentage: \" + str(total_correct_straat / total_straat * 100)+ \"%\")\n",
    "print(\"nummer: \" + str(total_correct_nummer) + \" percentage: \" + str(total_correct_nummer / total_nummer* 100)+ \"%\")\n",
    "print(\"city: \" + str(total_correct_city) + \" percentage: \" + str(total_correct_city / total_city* 100)+ \"%\")\n",
    "print(\"zipzode: \" + str(total_correct_zipcode) + \" percentage: \" + str(total_correct_zipcode / total_zipcode* 100)+ \"%\")\n",
    "print(\"state: \" + str(total_correct_state) + \" percentage: \" + str(total_correct_state / total_state* 100)+ \"%\")\n",
    "print(\"adress in list: \" + str(total_counter))\n",
    "\n",
    "# colors = {\"STREET\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", \"NUMBER\": \"linear-gradient(90deg, #3f5efb, #fc466b)\", \"ZIPCODE\": \"linear-gradient(90deg, #090979, #00d4ff)\", \"CITY\": \"linear-gradient(90deg, #eeaeca, #94bbe9)\", \"STATE\": \"linear-gradient(90deg, #22c1c3, #fdbb2d)\",}\n",
    "# options = {\"ents\": [\"CITY\", \"STREET\", \"NUMBER\", \"ZIPCODE\", \"STATE\"], \"colors\": colors}\n",
    "# displacy.serve(lijst, style=\"ent\", options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775a26a",
   "metadata": {},
   "source": [
    "### Bronnen\n",
    "<div>Hier is de lijst met bronnen die we gebruikt hebben om dit project te verwezelijken:</div>\n",
    "<div><a href=\"https://www.machinelearningplus.com/spacy-tutorial-nlp/\">https://www.machinelearningplus.com/spacy-tutorial-nlp/</a></div>\n",
    "<div><a href=\"https://machinelearningknowledge.ai/spacy-nlp-pipeline-tutorial-for-beginners/\">https://machinelearningknowledge.ai/spacy-nlp-pipeline-tutorial-for-beginners/</a> </div>\n",
    "<div><a href=\"https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\">https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/</a> </div>\n",
    "<div><a href=\"https://spacy.io/usage\">https://spacy.io/usage</a> </div>\n",
    "<div><a href=\"https://spacy.io/api/tokenizer\">https://spacy.io/api/tokenizer</a> </div>\n",
    "<div><a href=\"https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/#Adding_Special_Rule\">https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/#Adding_Special_Rule</a> </div>\n",
    "<div><a href=\"https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/custom-named-entity-recognition/how-to/improve-model\">https://docs.microsoft.com/en-us/azure/cognitive-services/language-service/custom-named-entity-recognition/how-to/improve-model</a> </div>\n",
    "<div><a href=\"https://thispointer.com/pandas-select-rows-without-nan-values/\">https://thispointer.com/pandas-select-rows-without-nan-values/</a> </div>\n",
    "<div><a href=\"https://www.creativeeurope.be/sites/creativeeurope/files/media/landencodes.pdf\">https://www.creativeeurope.be/sites/creativeeurope/files/media/landencodes.pdf</a> </div>\n",
    "<div><a href=\"https://regex101.com/\">https://regex101.com/</a> </div>\n",
    "<div><a href=\"https://www.geeksforgeeks.org/transliterating-non-ascii-characters-with-python/\">https://www.geeksforgeeks.org/transliterating-non-ascii-characters-with-python/</a> </div>\n",
    "<div><a href=\"https://spacy.io/usage/visualizers\">https://spacy.io/usage/visualizers</a> </div>\n",
    "<div><a href=\"https://www.askpython.com/python/examples/precision-and-recall-in-python\">https://www.askpython.com/python/examples/precision-and-recall-in-python</a> </div>\n",
    "<div><a href=\"https://cloudxlab.com/blog/numpy-pandas-introduction/\">https://cloudxlab.com/blog/numpy-pandas-introduction/</a> </div>\n",
    "<div><a href=\"https://realpython.com/pandas-dataframe/#accessing-and-modifying-data\">https://realpython.com/pandas-dataframe/#accessing-and-modifying-data</a> </div>\n",
    "<div><a href=\"https://www.tutorialspoint.com/spacy/index.htm\">https://www.tutorialspoint.com/spacy/index.htm</a> </div>\n",
    "<div><a href=\"https://realpython.com/natural-language-processing-spacy-python/\">https://realpython.com/natural-language-processing-spacy-python/</a> </div>\n",
    "<div><a href=\"https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\">https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/</a> </div>\n",
    "<div><a href=\"https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/\">https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/</a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
