{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6b7568",
   "metadata": {},
   "source": [
    "# Progress file for NER training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ec817",
   "metadata": {},
   "source": [
    "Install spacy in jupyter notebook env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c28127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (636 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/joachim/.local/lib/python3.8/site-packages (from spacy) (1.19.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy) (2.10.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/joachim/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/joachim/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: langcodes, pydantic, blis, wasabi, catalogue, srsly, cymem, murmurhash, preshed, thinc, typer, smart-open, pathy, tqdm, spacy-legacy, spacy-loggers, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.2 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 tqdm-4.62.3 typer-0.4.0 wasabi-0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383883c4",
   "metadata": {},
   "source": [
    "## Parsing a csv file with European addresses to spaCy readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1a9fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on street:  71\n",
      "failed on city:  616\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "with open('address.csv', newline=\"\\n\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',')\n",
    "    counter = 0 \n",
    "    f = open(\"result.py\", 'w')\n",
    "    f.write(\"TRAININGS_DATA = [\\n\")\n",
    "    f.close()\n",
    "    counter = 0\n",
    "    fail_numberstreet = 0\n",
    "    fail_cityzip = 0 \n",
    "    for row in csvreader:\n",
    "        correct = True\n",
    "        counter += 1\n",
    "        # print(row)\n",
    "        # exit()\n",
    "        counter +=1\n",
    "        # print(\"counter: \" + str(counter))\n",
    "        adres = ','.join(row)\n",
    "        adres = adres.replace(\",\", \";\")\n",
    "        # if re.match(\".*,.*,.*\", adres):\n",
    "            # print(adres)\n",
    "            # print(\"FUCK YOU\")\n",
    "        # else:\n",
    "        if not re.match(\".*,.*,.*\", adres):\n",
    "            # print(\"counter: \" + str(counter))\n",
    "            adreslengte = len(adres)\n",
    "            straat = row[0]\n",
    "            totale_lengte_straat = len(straat)\n",
    "            city = row[1]\n",
    "            straatposbegin = \"\"\n",
    "            straatposeind = \"\"\n",
    "            nummerposbegin =\"\"\n",
    "            nummerposeind = \"\"\n",
    "            cityposbegin = \"\"\n",
    "            cityposeind = \"\"\n",
    "            zipcodeposbegin =\"\"\n",
    "            zipcodeposeind =\"\"\n",
    "            # nummer + straat\n",
    "            # oud: ([0-9]+[A-Z]*)( )?([a-zA-Z]+)\n",
    "            # nieuw: (^[0-9]+.*([\\u00C0-\\u017Fa-zA-Z]+)),\n",
    "            # probeersel: ^([0-9]+)( .*)*( )([\\u00C0-\\u017Fa-zA-Z]+)\n",
    "            if re.match('^([0-9]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\']+)', straat):\n",
    "                split = re.search('^([0-9]+( ?bis)?) ([ \\u00C0-\\u017Fa-zA-Z\\']+)', straat)\n",
    "                splitstraat = split.group(3)\n",
    "                splitnummer = split.group(1)\n",
    "                straatlengte = len(splitstraat)\n",
    "                nummerlengte = len(splitnummer)\n",
    "                nummerposbegin = 0\n",
    "                nummerposeind = nummerlengte\n",
    "                straatposbegin = nummerposeind + 1\n",
    "                straatposeind = straatposbegin + straatlengte\n",
    "\n",
    "            # straat + nummer\n",
    "            # oude: ([a-zA-Z]+)( )?([0-9]+)\n",
    "            # nieuw: (([a-zA-Z]+) ([0-9]+.*,))\n",
    "            # oude nieuwe: ^([ \\u00C0-\\u017Fa-zA-Z\\']+) ([0-9]+( ?bis)?)\n",
    "            elif re.match('^([ \\u00C0-\\u017Fa-zA-Z\\']+) ([0-9\\/]+( ?[a-zA-Z]*)?)', straat):\n",
    "                split = re.search('^([ \\u00C0-\\u017Fa-zA-Z\\']+) ([0-9\\/]+( ?[a-zA-Z]*)?)', straat)\n",
    "                splitstraat = split.group(1)\n",
    "                splitnummer = split.group(2)\n",
    "                nummerlengte = len(splitnummer)\n",
    "                straatlengte = len(splitstraat)\n",
    "                straatposbegin = 0\n",
    "                straatposeind = straatlengte\n",
    "                nummerposbegin = straatlengte + 1\n",
    "                nummerposeind = nummerposbegin + nummerlengte\n",
    "            else:\n",
    "                fail_numberstreet +=1\n",
    "                correct = False\n",
    "            \n",
    "            # zipcode + city\n",
    "            # oud: ([A-Z]*-?[0-9]+)( )?([\\u00C0-\\u017Fa-zA-Z]+)\n",
    "            # nieuw: ([ A-Z-]*[0-9]+) ?([\\u00C0-\\u017Fa-zA-Z .\\/-]+)$\n",
    "            if re.match('([ A-Z-]*[0-9]+) ?([\\u00C0-\\u017Fa-zA-Z .\\/-¶¼]+)$', city):\n",
    "                split = re.search('([ A-Z-]*[0-9]+) ?([\\u00C0-\\u017Fa-zA-Z .\\/-¶¼]+)$', city)\n",
    "                splitcity = split.group(2)\n",
    "                splitzipcode = split.group(1)\n",
    "                # print(\"city: \" + splitcity)\n",
    "                # print(\"zipcode: \" + splitzipcode)\n",
    "                citylengte = len(splitcity)\n",
    "                zipcodelengte = len(splitzipcode)\n",
    "                zipcodeposbegin = totale_lengte_straat + 1\n",
    "                zipcodeposeind = zipcodeposbegin + zipcodelengte\n",
    "                cityposbegin = zipcodeposeind + 1\n",
    "                cityposeind = cityposbegin + citylengte\n",
    "\n",
    "            # city + zipcode \n",
    "            elif re.match('([\\u00C0-\\u017Fa-zA-Z .\\/-¶¼]+) ?([ A-Z-]*[0-9]+)$', city):\n",
    "                split = re.search('([\\u00C0-\\u017Fa-zA-Z .\\/-¶¼]+) ?([ A-Z-]*[0-9]+)$', city)\n",
    "                splitcity = split.group(1)\n",
    "                splitzipcode = split.group(2)\n",
    "                # print(\"city: \" + splitcity)\n",
    "                # print(\"zipcode: \" + splitzipcode)\n",
    "                zipcodelengte = len(splitzipcode)\n",
    "                citylengte = len(splitcity)\n",
    "                cityposbegin = totale_lengte_straat + 1\n",
    "                cityposeind = cityposbegin + citylengte\n",
    "                zipcodeposbegin = cityposeind + 1\n",
    "                zipcodeposeind = zipcodeposbegin + zipcodelengte\n",
    "            else:\n",
    "                fail_cityzip += 1\n",
    "                correct = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # city = row[1]\n",
    "        # citylengte = len(city)\n",
    "        # straatposbegin = 0\n",
    "        # straatposeind = straatlengte\n",
    "        # cityposbegin = straatlengte+1\n",
    "        # cityposeind = adreslengte\n",
    "        # # print(row[0] + \"length: \" + str(len(row[0])))\n",
    "            if correct:\n",
    "                f = open(\"result.py\", 'a')\n",
    "                f.write(\"\\t(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straatposbegin)+\",\"+str(straatposeind)+\", \\\"STREET\\\"),(\"+str(nummerposbegin)+\",\"+str(nummerposeind)+\", \\\"NUMBER\\\"),(\"+str(cityposbegin)+\",\"+str(cityposeind)+\", \\\"CITY\\\"),(\"+str(zipcodeposbegin)+\",\"+str(zipcodeposeind)+\", \\\"ZIPCODE\\\")]),\\n\")\n",
    "                f.close()\n",
    "            # print(\"(\\\"\"+adres+\"\\\",\"+\"[(\"+str(straatposbegin)+\",\"+str(straatposeind)+\", \\\"STREET\\\"),(\"+str(nummerposbegin)+\",\"+str(nummerposeind)+\", \\\"NUMBER\\\"),(\"+str(cityposbegin)+\",\"+str(cityposeind)+\", \\\"CITY\\\"),(\"+str(zipcodeposbegin)+\",\"+str(zipcodeposeind)+\", \\\"ZIPCODE\\\")])\")\n",
    "    f = open(\"result.py\", \"a\")\n",
    "    f.write(\"]\")\n",
    "    f.close()\n",
    "    print(\"failed on street: \", fail_numberstreet)\n",
    "    print(\"failed on city: \", fail_cityzip)\n",
    "        # (\"Reuterstr. 131,53113 Bonn\", [(0, 10, \"STREET\"), (11, 14, \"NUMBER\"), (15, 20, \"ZIPCODE\"), (21, 25, \"CITY\")],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da609486",
   "metadata": {},
   "source": [
    "### PrepareData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390a1c7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocBin\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TRAININGS_DATA\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from result import TRAININGS_DATA\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TRAININGS_DATA:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        print(token,end='; ')\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            print(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\" )\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    # print(ents)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./data/binaryData/train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40855e1",
   "metadata": {},
   "source": [
    "### PrepareData.py (write to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b398dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocBin\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TRAININGS_DATA \u001b[38;5;28;01mas\u001b[39;00m TD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from result import TRAININGS_DATA as TD\n",
    "from data.trainingData.AdressValidationData import training_data\n",
    "\n",
    "f = open(\"problems.txt\", 'w')\n",
    "f.close()\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "infixes = nlp.Defaults.infixes + [r'\\,']\n",
    "nlp.tokenizer.infix_finditer = spacy.util.compile_infix_regex(infixes).finditer\n",
    "\n",
    "# infixes = nlp.Defaults.infixes + [r'\\,',]\n",
    "# infix_reg = spacy.util.compile_infix_regex(infixes)\n",
    "# nlp.tokenizer.infix_finditer = infix_reg.finditer\n",
    "\n",
    "# suffixes = nlp.Defaults.suffixes + [r'(?<=[0-9]\\,)',]\n",
    "# suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "# nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "\n",
    "# prefixes = nlp.Defaults.prefixes + [r'(?<=[0-9]\\,)',]\n",
    "# prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
    "# nlp.tokenizer.prefix_search = prefix_regex.search\n",
    "\n",
    "\n",
    "db = DocBin()\n",
    "for text, annotations in TD:\n",
    "    doc = nlp(text)\n",
    "    # for token in doc:\n",
    "        # print(token,end='; ')\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            f = open(\"problems.txt\", 'a')\n",
    "            f.write(\"Problem:\" + doc.text + \" (\" + doc.text[start:end] + \")\\n\")\n",
    "            f.close()\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    # print(ents)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./data/binaryData/train.spacy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecaf75f",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59febd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     57.29   19.55   12.94   39.92    0.20\n",
      "  0     200        125.07   1981.01   99.16   98.94   99.39    0.99\n",
      "  1     400         90.49    201.01   99.76   99.68   99.84    1.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./config.cfg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaths.dev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/binaryData/train.spacy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/cli/train.py:75\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_path, output_path, use_gpu, overrides)\u001b[0m\n\u001b[1;32m     73\u001b[0m msg\u001b[38;5;241m.\u001b[39mgood(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialized pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m msg\u001b[38;5;241m.\u001b[39mdivider(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[43mtrain_nlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/loop.py:105\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(nlp, output_path, use_gpu, stdout, stderr)\u001b[0m\n\u001b[1;32m    103\u001b[0m     log_step, finalize_logger \u001b[38;5;241m=\u001b[39m train_logger(nlp, stdout, stderr)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, info, is_best_checkpoint \u001b[38;5;129;01min\u001b[39;00m training_step_iterator:\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_best_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mselect_pipes(disable\u001b[38;5;241m=\u001b[39mfrozen_components):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/loop.py:203\u001b[0m, in \u001b[0;36mtrain_while_improving\u001b[0;34m(nlp, optimizer, train_data, evaluate, dropout, eval_frequency, accumulate_gradient, patience, max_steps, exclude, annotating_components)\u001b[0m\n\u001b[1;32m    201\u001b[0m dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dropouts)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subbatch \u001b[38;5;129;01min\u001b[39;00m subdivide_batch(batch, accumulate_gradient):\n\u001b[0;32m--> 203\u001b[0m     \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotating_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# TODO: refactor this so we don't have to run it separately in here\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipeline:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py:1156\u001b[0m, in \u001b[0;36mLanguage.update\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline:\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1156\u001b[0m         \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sgd \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1159\u001b[0m             name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude\n\u001b[1;32m   1160\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proc, ty\u001b[38;5;241m.\u001b[39mTrainableComponent)\n\u001b[1;32m   1161\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mis_trainable\n\u001b[1;32m   1162\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1163\u001b[0m         ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/pipeline/tok2vec.py:164\u001b[0m, in \u001b[0;36mTok2Vec.update\u001b[0;34m(self, examples, drop, sgd, losses)\u001b[0m\n\u001b[1;32m    162\u001b[0m docs \u001b[38;5;241m=\u001b[39m [eg\u001b[38;5;241m.\u001b[39mpredicted \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m    163\u001b[0m set_dropout_rate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, drop)\n\u001b[0;32m--> 164\u001b[0m tokvecs, bp_tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m d_tokvecs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc2f(\u001b[38;5;241m*\u001b[39mt2v\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m t2v \u001b[38;5;129;01min\u001b[39;00m tokvecs]\n\u001b[1;32m    166\u001b[0m losses\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:309\u001b[0m, in \u001b[0;36mModel.begin_update\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable[[InT], OutT]]:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124;03m\"\"\"Run the model over a batch of data, returning the output and a\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    callback to complete the backward pass. A tuple (Y, finish_update),\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    where Y is a batch of output data, and finish_update is a callback that\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    takes the gradient with respect to the output and an optimizer function,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    and returns the gradient with respect to the input.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/with_array.py:40\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mList2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mList2d\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/with_array.py:76\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     74\u001b[0m lengths \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     75\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: List2d) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List2d:\n\u001b[1;32m     79\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/residual.py:40\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 40\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/thinc/layers/maxout.py:49\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     47\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[0;32m---> 49\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[1;32m     51\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from spacy.cli.train import train\n",
    "\n",
    "train(\"./config.cfg\", \"./output\", overrides={\"paths.dev\": \"./data/binaryData/train.spacy\"})\n",
    "# train(\"./config.cfg\", \"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986c0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
